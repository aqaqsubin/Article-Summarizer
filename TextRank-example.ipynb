{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextRank-example.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPG96oz0+pAlbOWrW1gF7bP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OEie_9UJFj7Y"},"source":["### **필요한 라이브러리 설치**\n","  \n","\n","> jpye1 : konlpy 설치를 위해 필요한 라이브러리  \n",">  konlpy : 한글 텍스트 전처리 라이브러리  \n",">  scikit-learn : TF-IDF 테이블 생성을 위해 필요한 라이브러리"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlVBgTbQToLX","executionInfo":{"status":"ok","timestamp":1610370889195,"user_tz":-540,"elapsed":12208,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"497db4e0-55eb-4f02-8cc4-ec1b5400f43f"},"source":["!pip install jpype1\n","!pip install konlpy\n","!pip install scikit-learn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting jpype1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n","\r\u001b[K     |▊                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 245kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 256kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 266kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 276kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 286kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 296kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 307kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 317kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 327kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 337kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 348kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 358kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 368kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 378kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 389kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 399kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 409kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 419kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 430kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 440kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 450kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 460kB 4.2MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jpype1) (3.7.4.3)\n","Installing collected packages: jpype1\n","Successfully installed jpype1-1.2.1\n","Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.1)\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: colorama, tweepy, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCmH5YGTTwCv","executionInfo":{"status":"ok","timestamp":1610370891624,"user_tz":-540,"elapsed":14626,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"b61bdd22-4336-488d-b18f-abf5379c8868"},"source":["from konlpy.tag import Kkma\n","from konlpy.tag import Twitter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import normalize\n","import numpy as np\n","import os\n","import re\n","import nltk\n","import os\n","from konlpy.tag import Okt\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import RegexpTokenizer\n","from shutil import rmtree\n","\n","nltk.download('punkt')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"7qoFY5pAGQm2"},"source":["### 경로 설정\n","\n","BASE_DIR : 원본 데이터, 전처리 데이터를 저장하는 상위 디렉토리 경로  \n","TARGET_PATH : 전처리 데이터를 저장하는 경로  \n","ARTICLE_MEDIA_PATH : 원본 데이터를 저장하는 경로  \n","SWORDS_FILE_PATH : 불용어 리스트를 저장하는 텍스트 파일 경로  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfcmGp7FVNsz","executionInfo":{"status":"ok","timestamp":1610370917542,"user_tz":-540,"elapsed":40537,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"12c856a3-8e7b-442f-a3b8-179521b718b0"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hDhYmVxCqUtn","executionInfo":{"status":"ok","timestamp":1610370917543,"user_tz":-540,"elapsed":40535,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["BASE_DIR = \"/content/gdrive/My Drive/Colab Notebooks/Text-preprocessing-Data/\"\n","TARGET_PATH = os.path.join(BASE_DIR,\"preprocessed\")\n","ARTICLE_MEDIA_PATH = os.path.join(BASE_DIR,\"articles\")\n","SWORDS_FILE_PATH = os.path.join(BASE_DIR, \"StopWordList.txt\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTqYI8I-LXaZ"},"source":["디렉토리 생성 및 삭제 함수"]},{"cell_type":"code","metadata":{"id":"OYFL5H1vqcRX","executionInfo":{"status":"ok","timestamp":1610370917543,"user_tz":-540,"elapsed":40532,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["def mkdir_p(path):\n","    import errno\n","    try:\n","        os.makedirs(path)\n","    except OSError as exc:\n","        if exc.errno == errno.EEXIST and os.path.isdir(path):\n","            pass\n","        else:\n","            raise\n","\n","\n","def del_folder(path):\n","    try:\n","        rmtree(path)\n","    except:\n","        pass\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBSMmCQarRbM","executionInfo":{"status":"ok","timestamp":1610370917544,"user_tz":-540,"elapsed":40530,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["def text2Sentences(text):\n","  return text.split('/')\n","\n","def sentences2Text(sentences):\n","  return '/'.join([sentence for sentence in sentences])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"52NHu6wV9jx_","executionInfo":{"status":"ok","timestamp":1610370917544,"user_tz":-540,"elapsed":40527,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["def readArticle(filename):\n","\n","    f = open(filename, 'r', encoding='utf-8')\n","    title = f.readline()[:-1]\n","    content = f.readline()[:-1]\n","    media = f.readline()[:-1]\n","    f.close()\n","\n","    return title, media, content\n","\n","def cleanContent(content, media):\n","    content = re.sub('\\s+', ' ', content)  # 중복 공백, 탭, 개행 제거\n","    content = re.sub(r'\\([^)]*\\)', '', content)  # 괄호 안 숫자 제거\n","    content = content.replace(media, '')  # 언론사명 제거\n","\n","    return content\n","\n","def removeSpecialChar(text):\n","    retokenize = RegexpTokenizer(\"[\\w]+\")\n","    return ' '.join(retokenize.tokenize(text))\n","\n","def getStopWord(swords_filename):\n","    swords = []\n","    with open(swords_filename, 'r') as f:\n","        swords = f.readlines()\n","        swords = [sword.strip() for sword in swords]\n","\n","    return swords\n","\n","def delStopWord(sentence):\n","    if sentence is '':\n","        return None\n","\n","    okt = Okt()\n","    swords = getStopWord(SWORDS_FILE_PATH)\n","    return ' '.join([word for word in okt.morphs(sentence) if word not in swords and len(word) > 1])\n","\n","def getRmSwordSentences(sentences):\n","    rmSwordSentences = []\n","    for sentence in sentences:\n","        sentence = delStopWord(sentence)\n","        if sentence is not None : rmSwordSentences.append(sentence)\n","        print(len(rmSwordSentences))\n","    return rmSwordSentences\n","\n","def getNouns(sentences):\n","  \n","  okt = Okt()\n","  swords = getStopWord(SWORDS_FILE_PATH)\n","\n","  nouns = []\n","  for sentence in sentences:\n","    if sentence is not '':\n","      nouns.append(' '.join([noun for noun in okt.morphs(sentence) if noun not in swords and len(noun) > 1]))\n","  return nouns\n","\n","\n","def savePreprocessedText(media, article, nouns):\n","\n","    mkdir_p(os.path.join(TARGET_PATH, media))\n","    save_path = os.path.join(os.path.join(TARGET_PATH, media), article)\n","\n","    with open(save_path, 'w') as f:\n","        f.write(title)\n","        preprocessed = \"\"\n","        for noun in nouns:\n","            preprocessed += noun + \"/\"\n","        f.write(preprocessed)\n","        print(preprocessed+\"\\n\")\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhhUGPV7ryfC","executionInfo":{"status":"ok","timestamp":1610370917545,"user_tz":-540,"elapsed":39930,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["class GraphMatrix(object):\n","  def __init__(self):\n","    self.tfidf = TfidfVectorizer()\n","    self.cnt_vec = CountVectorizer()\n","    self.graph_sentence = []\n","  \n","  def build_sent_graph(self, sentences):\n","\n","    tfidf_mat = self.tfidf.fit_transform(sentences).toarray()\n","    \n","    self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n","    return self.graph_sentence\n","  \n","  def build_words_graph(self, sentence):\n","    cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n","\n","    vocab = self.cnt_vec.vocabulary_\n","    return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQwNN3ci182m","executionInfo":{"status":"ok","timestamp":1610370917545,"user_tz":-540,"elapsed":38313,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["class Rank(object):\n","  def get_ranks(self, graph, d=0.85):\n","    A = graph\n","    matrix_size = A.shape[0]\n","    for id in range(matrix_size):\n","      A[id,id] = 0\n","      link_sum = np.sum(A[:,id])\n","      if link_sum != 0:\n","        A[:, id] /= link_sum\n","      A[:, id] *= -d\n","      A[id, id] = 1\n","    B = (1-d) * np.ones((matrix_size, 1))\n","    ranks = np.linalg.solve(A, B)\n","    return {idx: r[0] for idx, r in enumerate(ranks)}\n","  "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"jO-cOFiA18ce","executionInfo":{"status":"ok","timestamp":1610370917545,"user_tz":-540,"elapsed":37548,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["class TextRank(object):\n","  def __init__(self, text):\n","    self.sentences = text2Sentences(text)\n","    print(\"Get Sentences\")\n","    self.nouns = getNouns(self.sentences)\n","\n","    print(\"Get Nouns\")\n","    self.graph_matrix = GraphMatrix()\n","    print(\"Construct GraphMatrix\")\n","    self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n","    print(\"Sent Graph\")\n","    self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n","    print(\"Word Graph\")\n","    self.rank = Rank()\n","    print(\"Construct Rank\")\n","    self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n","    self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n","\n","    self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n","    self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx)\n","\n","  def summarize(self, sent_num=3):\n","    summary = []\n","    index =[]\n","    for idx in self.sorted_sent_rank_idx[:sent_num]:\n","      index.append(idx)\n","    index.sort()\n","\n","    for idx in index:\n","      summary.append(self.sentences[idx])\n","\n","    return summary\n","  \n","  def keywords(self, word_num=10):\n","    rank = Rank()\n","    rank_idx = rank.get_ranks(self.words_graph)\n","\n","    sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n","\n","    keywords = []\n","    index = []\n","    for idx in sorted_rank_idx[:word_num]:\n","      index.append(idx)\n","    \n","    for idx in index:\n","      keywords.append(self.idx2word[idx])\n","    return keywords"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAUmdKQQ74Rp","outputId":"090dffbe-a446-41ee-c790-8d81f8ca9e1b"},"source":["media_list = os.listdir(ARTICLE_MEDIA_PATH)\n","media_path= os.path.join(ARTICLE_MEDIA_PATH, media_list[0])\n","\n","document = os.listdir(media_path)[0]\n","title, media, content = readArticle(os.path.join(media_path, document))\n","content = cleanContent(content, media)\n","\n","sentences = sent_tokenize(content)\n","sentences = [removeSpecialChar(sentence) for sentence in sentences]\n","text = sentences2Text(sentences)\n","\n","textrank = TextRank(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Get Sentences\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4za8-lReSPVI"},"source":["for row in textrank.summarize(2):\n","  print(row+'\\n')"],"execution_count":null,"outputs":[]}]}