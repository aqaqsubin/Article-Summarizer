{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lZajwNuSy6CL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer/CommonModule/Handle_Dir.ipynb\n",
      "importing Jupyter notebook from /data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer/CommonModule/Encoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from S2S_Attention import Encoder, Decoder\n",
    "from Transformer.CommonModule.Handle_Dir import mkdir_p, del_folder\n",
    "from Transformer.CommonModule.Encoder import IntegerEncoder\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from glob import iglob\n",
    "import sentencepiece as spm\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5bQpTi6Ooimh"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb/\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "SRC_BASE_DIR = os.path.join(BASE_DIR, 'TestSampleDir')\n",
    "\n",
    "TITLE_PREPROCESSED_PATH= os.path.join(DATA_BASE_DIR,\"Title-Preprocessed-Data\")\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "\n",
    "WORD_ENCODING_DIR = os.path.join(os.path.join(SRC_BASE_DIR, 'articleSummary-Jupyter'), 'Word-Encoding-Model')\n",
    "MODEL_DIR = os.path.join(SRC_BASE_DIR, 'Transformer-Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pI6rh2qoY-m",
    "outputId": "6ff6ef78-d98a-4cd4-b57b-c504751c5728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "model_num = len(list(iglob(os.path.join(WORD_ENCODING_DIR, 'spm-input-*.vocab'), recursive=False))) -1\n",
    "sp.Load(os.path.join(WORD_ENCODING_DIR, 'spm-input-{}.model').format(model_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOOdALmPoZAt"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 70000\n",
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dpn4ucGdoZCr",
    "outputId": "6a828e5f-f143-4598-fa3d-e23f3817f397"
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    'model-type' : 'Sentence-Piece',\n",
    "    'inv_wv' : None,\n",
    "    'corpus' : None,\n",
    "    'spm' : sp\n",
    "}\n",
    "output_encoded_list = IntegerEncoder(options=options, filepaths=list(iglob(os.path.join(TITLE_PREPROCESSED_PATH, '**.csv'), recursive=False))).encoder()\n",
    "input_encoded_list = IntegerEncoder(options=options, filepaths=list(iglob(os.path.join(SUMMARY_PREPROCESSED_PATH, '**.csv'), recursive=False))).encoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_length = lambda x : np.max([len(line) for line in x])\n",
    "\n",
    "MAX_LEN = get_max_length(input_encoded_list)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUMMARY_MAX_LEN = get_max_length(output_encoded_list)\n",
    "SUMMARY_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 5000\n",
    "\n",
    "EPOCHS = 30\n",
    "ENC_UNITS = 128\n",
    "DEC_UNITS = ENC_UNITS * 2\n",
    "\n",
    "START_TOKEN = [sp.bos_id()]\n",
    "END_TOKEN = [sp.eos_id()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_list = list(map(lambda list_ : START_TOKEN + list_ + END_TOKEN, input_encoded_list))\n",
    "output_encoded_list = list(map(lambda list_ : START_TOKEN + list_ + END_TOKEN, output_encoded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN+=2\n",
    "SUMMARY_MAX_LEN+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "input_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    input_encoded_list, maxlen=MAX_LEN, padding='post')\n",
    "output_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    output_encoded_list, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Shape : (28323, 192)\n",
      "Title Shape : (28323, 192)\n"
     ]
    }
   ],
   "source": [
    "print('Summary Shape : {}'.format(input_encoded_matrix.shape))\n",
    "print('Title Shape : {}'.format(output_encoded_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_encoded_matrix, output_encoded_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 192]), TensorShape([64, 192]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp)\n",
    "\n",
    "        dec_hidden = enc_hidden[0]\n",
    "\n",
    "        # print(\"dec_hidden shape : {}\".format(dec_hidden))\n",
    "\n",
    "        dec_input = tf.expand_dims(START_TOKEN * BATCH_SIZE, 1)\n",
    "\n",
    "        # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # enc_output를 디코더에 전달합니다.\n",
    "            #   print(\"enc_output shape : {}\".format(enc_output))\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            #   print(\"dec_hidden shape : {}\".format(dec_hidden.shape))\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # 교사 강요(teacher forcing)를 사용합니다.\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 192, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 256)\n",
      "Encoder Cell state shape: (batch size, units) (64, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(VOCAB_SIZE, D_MODEL, ENC_UNITS, BATCH_SIZE, cell='lstm')\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    sample_output, sample_hidden = encoder(example_input_batch)\n",
    "    print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "    print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden[0].shape))\n",
    "    print ('Encoder Cell state shape: (batch size, units) {}'.format(sample_hidden[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 70000)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(VOCAB_SIZE, D_MODEL, DEC_UNITS, BATCH_SIZE, cell='lstm')\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    hidden = sample_hidden[0]\n",
    "    sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                          hidden, sample_output)\n",
    "\n",
    "    print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.6764\n",
      "Epoch 1 Batch 100 Loss 0.4685\n",
      "Epoch 1 Batch 200 Loss 0.4890\n",
      "Epoch 1 Batch 300 Loss 0.4790\n",
      "Epoch 1 Batch 400 Loss 0.4476\n",
      "Epoch 1 Loss 0.4900\n",
      "Time taken for 1 epoch 595.5211997032166 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.4859\n",
      "Epoch 2 Batch 100 Loss 0.4396\n",
      "Epoch 2 Batch 200 Loss 0.4473\n",
      "Epoch 2 Batch 300 Loss 0.4520\n",
      "Epoch 2 Batch 400 Loss 0.4371\n",
      "Epoch 2 Loss 0.4454\n",
      "Time taken for 1 epoch 380.66272926330566 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4624\n",
      "Epoch 3 Batch 100 Loss 0.4278\n",
      "Epoch 3 Batch 200 Loss 0.4096\n",
      "Epoch 3 Batch 300 Loss 0.4292\n",
      "Epoch 3 Batch 400 Loss 0.4141\n",
      "Epoch 3 Loss 0.4205\n",
      "Time taken for 1 epoch 386.43679022789 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4272\n",
      "Epoch 4 Batch 100 Loss 0.4231\n",
      "Epoch 4 Batch 200 Loss 0.3939\n",
      "Epoch 4 Batch 300 Loss 0.3936\n",
      "Epoch 4 Batch 400 Loss 0.3839\n",
      "Epoch 4 Loss 0.4006\n",
      "Time taken for 1 epoch 387.2936415672302 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4211\n",
      "Epoch 5 Batch 100 Loss 0.3835\n",
      "Epoch 5 Batch 200 Loss 0.3662\n",
      "Epoch 5 Batch 300 Loss 0.3503\n",
      "Epoch 5 Batch 400 Loss 0.3820\n",
      "Epoch 5 Loss 0.3843\n",
      "Time taken for 1 epoch 384.2634208202362 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4001\n",
      "Epoch 6 Batch 100 Loss 0.3701\n",
      "Epoch 6 Batch 200 Loss 0.3315\n",
      "Epoch 6 Batch 300 Loss 0.3739\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "BUFFER_SIZE = input_encoded_matrix.shape[0]\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    for epoch in range(EPOCHS): \n",
    "        start = time.time()\n",
    "\n",
    "#         enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            batch_loss = train_step(inp, targ)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "        # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                          total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((SUMMARY_MAX_LEN, MAX_LEN))\n",
    "\n",
    "\n",
    "    inputs = sp.encode_as_ids(sentence)\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=MAX_LEN,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    \n",
    "    enc_out, enc_stats = encoder(inputs)\n",
    "    \n",
    "#     enc_hidden_stat = enc_stats\n",
    "\n",
    "    enc_hidden_stat = enc_stats[0]\n",
    "    enc_cell_stat = enc_stats[1]\n",
    "\n",
    "    print(enc_hidden_stat.shape)\n",
    "\n",
    "    dec_hidden = enc_hidden_stat\n",
    "    dec_input = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    idx_list = []\n",
    "    for t in range(SUMMARY_MAX_LEN):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장합니다.\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        # print(sp.decode_ids([predicted_id]))\n",
    "\n",
    "        # result += sp.decode_ids([predicted_id])[0] + ' '\n",
    "        idx_list.append(int(predicted_id))\n",
    "\n",
    "        if [predicted_id] == END_TOKEN:\n",
    "            return ' '.join(sp.decode_ids(idx_list)), sentence, attention_plot\n",
    "\n",
    "        # 예측된 ID를 모델에 다시 피드합니다.\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return ' '.join(sp.decode_ids(idx_list)), sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ZKdoSsZ76pdr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "path = './NanumBarunGothic.ttf'\n",
    "\n",
    "# 어텐션 가중치를 그리기 위한 함수입니다.\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'family': 'NanumBarunGothic', 'fontsize': 14}\n",
    "    fontprop = fm.FontProperties(fname = path, size=18)\n",
    "\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontproperties=fontprop, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontproperties=fontprop, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE4A_4rcn_qU",
    "outputId": "a59be689-7631-41bc-cddd-cadbcb8ac241"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBoWYFw7oPQx",
    "outputId": "4b3d9160-1df5-44b7-bd43-14f8382a7877"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa33899ecee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"이 아이의 장기판매도 가능하다는 글도 덧붙였다 4분 뒤 우리집 내 딸 판매합니다 라는 제목의 글이 또 올라왔다\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'translate' is not defined"
     ]
    }
   ],
   "source": [
    "translate(\"이 아이의 장기판매도 가능하다는 글도 덧붙였다 4분 뒤 우리집 내 딸 판매합니다 라는 제목의 글이 또 올라왔다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Base-S2S",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
