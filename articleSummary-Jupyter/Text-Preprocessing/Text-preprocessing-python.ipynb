{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11031,
     "status": "ok",
     "timestamp": 1610755022118,
     "user": {
      "displayName": "김수빈",
      "photoUrl": "",
      "userId": "17754099482493494628"
     },
     "user_tz": -540
    },
    "id": "X_cwe5iCxSDp",
    "outputId": "ae645a99-4108-4327-fd39-02f261a0ce43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\aqaq9\\Documents\\Article-Summarizer\\articleSummary-Jupyter\\Text-Preprocessing\\CommonModule\\Handle_Dir.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\aqaq9\\Documents\\Article-Summarizer\\articleSummary-Jupyter\\Text-Preprocessing\\CommonModule\\ArticleHandler.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aqaq9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# _*_ coding: utf-8 _*_\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "import import_ipynb\n",
    "from CommonModule.Handle_Dir import mkdir_p, del_folder\n",
    "from CommonModule.ArticleHandler import Article, ArticleReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 30350,
     "status": "ok",
     "timestamp": 1610755041467,
     "user": {
      "displayName": "김수빈",
      "photoUrl": "",
      "userId": "17754099482493494628"
     },
     "user_tz": -540
    },
    "id": "sxJDqNbWxam3"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/TestDir/sample_articles\"\n",
    "ORIGIN_PATH = os.path.join(BASE_DIR,\"Origin-Data\")\n",
    "PREPROCESSED_PATH = os.path.join(BASE_DIR,\"Preprocessed-Data\")\n",
    "PRETTY_PATH = os.path.join(BASE_DIR,\"Pretty-Data\")\n",
    "SWORDS_PATH = os.path.join(BASE_DIR, \"StopWordList.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.retokenize = RegexpTokenizer(\"[\\w]+\")\n",
    "        self.swords = []\n",
    "        self.tokenizer = {}\n",
    "        self.tagger = Komoran()\n",
    "\n",
    "    def removeDuplicateSpace(self, text):\n",
    "        return re.sub('\\s+', ' ', text)  # 중복 공백, 탭, 개행 제거\n",
    "    \n",
    "    def removeSpecialChar(self, text):\n",
    "        return ' '.join(self.retokenize.tokenize(text))\n",
    "\n",
    "\n",
    "    def loadSwords(self, filename):\n",
    "        self.swords = []\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            swords = f.readlines()\n",
    "            self.swords = [sword.strip() for sword in self.swords]\n",
    "\n",
    "        self.tokenizer = lambda sent: filter(lambda x:x not in self.swords, sent.split())\n",
    "\n",
    "        return self.swords\n",
    "        \n",
    "    def removeSwords(self, text):\n",
    "        return ' '.join([token for token in list(self.tokenizer(text))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1610755060586,
     "user": {
      "displayName": "김수빈",
      "photoUrl": "",
      "userId": "17754099482493494628"
     },
     "user_tz": -540
    },
    "id": "Do4uaXoBxbl_"
   },
   "outputs": [],
   "source": [
    "def saveTextFile(baseDir, media, filename, sentences):\n",
    "\n",
    "    mkdir_p(os.path.join(baseDir, media))\n",
    "    save_path = os.path.join(os.path.join(baseDir, media), filename)\n",
    "\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('/n'.join([sentence for sentence in sentences if sentence is not '']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16841,
     "status": "ok",
     "timestamp": 1610756325623,
     "user": {
      "displayName": "김수빈",
      "photoUrl": "",
      "userId": "17754099482493494628"
     },
     "user_tz": -540
    },
    "id": "dZXr_0LWxY52",
    "outputId": "1f59102c-9394-43c3-ecb8-8679a4981ef1"
   },
   "outputs": [],
   "source": [
    "del_folder(PREPROCESSED_PATH)\n",
    "del_folder(PRETTY_PATH)\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "preprocessor.loadSwords(SWORDS_PATH)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    media_list = sorted(os.listdir(ORIGIN_PATH))\n",
    "\n",
    "    for media_name in media_list:\n",
    "\n",
    "        media_path = os.path.join(ORIGIN_PATH, media_name)\n",
    "        article_list = sorted(os.listdir(media_path))\n",
    "\n",
    "        for article_name in article_list:\n",
    "            reader = ArticleReader(os.path.join(media_path, article_name))\n",
    "\n",
    "            article = Article(list(filter(None, reader)))\n",
    "            \n",
    "            if len(article.content) is 0 : continue # 본문이 없는 경우, 학습 데이터에서 제외함\n",
    "            \n",
    "            prettyLine = []\n",
    "            preprocessedLine = []\n",
    "            for line in article.readContent() :\n",
    "                cleanLine = preprocessor.removeDuplicateSpace(line)\n",
    "                cleanLine = preprocessor.removeSpecialChar(cleanLine)\n",
    "                \n",
    "                rmSwordLine = preprocessor.removeSwords(cleanLine)\n",
    "                if rmSwordLine is '': continue\n",
    "                    \n",
    "                preprocessedLine.append(rmSwordLine)\n",
    "\n",
    "            saveTextFile(PREPROCESSED_PATH, media_name, article_name, preprocessedLine)\n",
    "            saveTextFile(PRETTY_PATH, media_name, article_name, article.readContent())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnJhI3kxyw2hvIausnF+TX",
   "collapsed_sections": [],
   "name": "Text-preprocessing-python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
