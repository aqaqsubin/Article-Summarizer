{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word2vec.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNHwZs9X430hTG6GBhxGSlc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SO4KCOQ-hoZZ"},"source":["### **Word2Vec**\n","\n","원 핫 인코딩을 사용하면서도 단어 간 유사도를 반영할 수 있도록 단어의 의미를 벡터화하는 방법이다.\n","\n","*비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다*는 분포 가설을 따르는 분산 표현 방법을 사용한다.\n","\n","예) '강아지'는 주로 '귀엽다','예쁘다' 등의 단어와 함께 등장하는데, 이러한 내용을 가지는 텍스트를 벡터화하면 이 단어들은 의미적으로 가까운 단어가 된다.\n","\n","<br>\n","Word2Vec에는 다음 두 가지 방식이 있다.  \n","\n","- CBOW(Continous Bag of Words)\n","- Skip-Gram\n"]},{"cell_type":"markdown","metadata":{"id":"XTU4BoNByfsG"},"source":["#### **CBOW(Continous Bag of Words)**\n","\n","주변에 있는 단어들을 통해 중간에 있는 단어를 예측하는 방법이다.  \n","윈도우를 두고, 윈도우 내의 주변 단어의 벡터로 중심 단어의 벡터를 예측한다.    \n","Skip-Gram에 비해 몇 배 빠른 훈련이 가능하며, 빈번한 단어를 예측하는 데 더 나은 정확도를 가진다."]},{"cell_type":"code","metadata":{"id":"yl1OQabAhiT-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610756365243,"user_tz":-540,"elapsed":3443,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"cb8c5738-08ad-4cd6-a7b1-7275b1cf5b78"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"r3LX4JRFRnSm"},"source":["import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYT0NnchTJ_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610757453191,"user_tz":-540,"elapsed":18837,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"a955a51c-359c-4ed9-d89d-2b73dc0af1b7"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h758V3xnOn-a","executionInfo":{"status":"ok","timestamp":1610757453193,"user_tz":-540,"elapsed":18834,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["BASE_DIR = \"/content/gdrive/My Drive/Colab Notebooks/ETRI_Article_Summarizer/Text-preprocessing-Data/articles\"\n","ORIGIN_PATH = os.path.join(BASE_DIR,\"Origin-Data\")\n","PREPROCESSED_PATH = os.path.join(BASE_DIR,\"Preprocessed-Data\")\n","PRETTY_PATH = os.path.join(BASE_DIR,\"Pretty-Data\")\n","SWORDS_PATH = os.path.join(BASE_DIR, \"StopWordList.txt\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxk7uMs3TcNt","executionInfo":{"status":"ok","timestamp":1610757453193,"user_tz":-540,"elapsed":18828,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["class RawTextReader:\n","    def __init__(self, filepath):\n","        self.filepath = filepath\n","        self.rgxSplitter = re.compile(\"/n\")\n","\n","    def __iter__(self):\n","        for line in open(self.filepath, encoding='utf-8'):\n","            ch = self.rgxSplitter.split(line)\n","            for s in ch:\n","                yield s"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NK0e5jvhRUdx"},"source":["경향신문 언론사 첫번째 기사를 예시로 전처리된 텍스트를 토큰화 한다."]},{"cell_type":"code","metadata":{"id":"78RoyzFkRKhH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610757459301,"user_tz":-540,"elapsed":2275,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"305224f3-6e2a-4290-e4ab-2d4c3e467df3"},"source":["media_list = os.listdir(ORIGIN_PATH)\n","\n","media = media_list[2]\n","media_path = os.path.join(PREPROCESSED_PATH, media)\n","article_list= os.listdir(media_path)\n","\n","article = article_list[0]\n","reader = RawTextReader(os.path.join(media_path, article))\n","    \n","content = list(filter(None, reader))\n","content"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['김창룡 경찰청장 오늘 생후 여아 부모 학대 숨지 정인 사건 과 관련 국민 사과문 발표',\n"," '김 청장 경찰 청사 브리핑 열 숨지 정인 양의 명복 비 학대 피해 보 어린아이 생명 보호 깊 사죄 말씀 드리 말',\n"," '김 청장 초동 대응 수사 과정 부분 대하 경찰 최고 책임자 깊 책임감 느끼 진상 조사 바탕 재발 방지 대책 마련 경찰 아동 학대 대응 체계 전면 쇄신 계기 삼 말',\n"," '김 청장 이번 사건 대하 지휘 책임 묻 양천 경찰서장 대기발령 조치 후임 여성 청소년 분야 정통 서울 경찰청 총경 발령 밝히',\n"," '지난해 10월 발생 입양아 학대 사망 사건 지나 그것이 알고 싶다 통하 조명 사회 분노 확산',\n"," '청와대 국민 청원 게시판 올라오 아동 학대 방조 양천 경찰서장 담당 경찰관 파면 요구 제목 글 게시 하루 정부 공식 답변 요건 이상 동의 얻']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fBUXNIoT-P3","executionInfo":{"status":"ok","timestamp":1610757459302,"user_tz":-540,"elapsed":1256,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"3cbac0ed-1ca3-42ba-eb11-000944d9d4cb"},"source":["tokenList = [sent.split() for sent in content]\n","tokenList"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['김창룡',\n","  '경찰청장',\n","  '오늘',\n","  '생후',\n","  '여아',\n","  '부모',\n","  '학대',\n","  '숨지',\n","  '정인',\n","  '사건',\n","  '과',\n","  '관련',\n","  '국민',\n","  '사과문',\n","  '발표'],\n"," ['김',\n","  '청장',\n","  '경찰',\n","  '청사',\n","  '브리핑',\n","  '열',\n","  '숨지',\n","  '정인',\n","  '양의',\n","  '명복',\n","  '비',\n","  '학대',\n","  '피해',\n","  '보',\n","  '어린아이',\n","  '생명',\n","  '보호',\n","  '깊',\n","  '사죄',\n","  '말씀',\n","  '드리',\n","  '말'],\n"," ['김',\n","  '청장',\n","  '초동',\n","  '대응',\n","  '수사',\n","  '과정',\n","  '부분',\n","  '대하',\n","  '경찰',\n","  '최고',\n","  '책임자',\n","  '깊',\n","  '책임감',\n","  '느끼',\n","  '진상',\n","  '조사',\n","  '바탕',\n","  '재발',\n","  '방지',\n","  '대책',\n","  '마련',\n","  '경찰',\n","  '아동',\n","  '학대',\n","  '대응',\n","  '체계',\n","  '전면',\n","  '쇄신',\n","  '계기',\n","  '삼',\n","  '말'],\n"," ['김',\n","  '청장',\n","  '이번',\n","  '사건',\n","  '대하',\n","  '지휘',\n","  '책임',\n","  '묻',\n","  '양천',\n","  '경찰서장',\n","  '대기발령',\n","  '조치',\n","  '후임',\n","  '여성',\n","  '청소년',\n","  '분야',\n","  '정통',\n","  '서울',\n","  '경찰청',\n","  '총경',\n","  '발령',\n","  '밝히'],\n"," ['지난해',\n","  '10월',\n","  '발생',\n","  '입양아',\n","  '학대',\n","  '사망',\n","  '사건',\n","  '지나',\n","  '그것이',\n","  '알고',\n","  '싶다',\n","  '통하',\n","  '조명',\n","  '사회',\n","  '분노',\n","  '확산'],\n"," ['청와대',\n","  '국민',\n","  '청원',\n","  '게시판',\n","  '올라오',\n","  '아동',\n","  '학대',\n","  '방조',\n","  '양천',\n","  '경찰서장',\n","  '담당',\n","  '경찰관',\n","  '파면',\n","  '요구',\n","  '제목',\n","  '글',\n","  '게시',\n","  '하루',\n","  '정부',\n","  '공식',\n","  '답변',\n","  '요건',\n","  '이상',\n","  '동의',\n","  '얻']]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"UPusT7V8QEbe"},"source":["#### **Word2Vec 학습**\n","\n","gensim에서는 다음과 같이 Word2Vec을 지원한다.  \n","\n","> `sentences` : 단어 토큰화된 문장\n","> `size` : Projection Layer의 크기, 임베딩 벡터의 차원  \n","> `window` : 윈도우 크기  \n","> `min_count` : 단어의 최소 빈도 수, 이 이하의 빈도를 가지는 단어는 학습하지 않음  \n","> `workers` : 학습을 위한 프로세스 수  \n","> `sg` : 0일 경우 CBOW, 1일 경우 Skip-Gram  \n","\n"]},{"cell_type":"code","metadata":{"id":"a7C0w-C_QCfk","executionInfo":{"status":"ok","timestamp":1610757698936,"user_tz":-540,"elapsed":644,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(sentences=tokenList, size=100, window=5, min_count=1, workers=4, sg=0)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7_IFrJx9pC-l"},"source":["'어린아이'를 입력했을 때 의미가 유사한 단어들을 출력합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ7V1sgcovMX","executionInfo":{"status":"ok","timestamp":1610757815845,"user_tz":-540,"elapsed":725,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"32586738-59c3-401f-e35b-8820b785a048"},"source":["model_result = model.wv.most_similar(\"어린아이\")\r\n","model_result"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('통하', 0.23341265320777893),\n"," ('생명', 0.19156435132026672),\n"," ('보', 0.1762913167476654),\n"," ('정부', 0.16928637027740479),\n"," ('체계', 0.1687452793121338),\n"," ('담당', 0.15607227385044098),\n"," ('지난해', 0.14923827350139618),\n"," ('진상', 0.14879366755485535),\n"," ('사건', 0.1381472647190094),\n"," ('오늘', 0.1326114386320114)]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"p2IRZsuRpjxw"},"source":["#### **Skip-Gram**\r\n","\r\n","중심 단어를 통해 주변에 있는 단어들을 예측하는 방법이다.  \r\n","소량의 학습 데이터에서도 잘 동작하며, 자주 사용하지 않는 희귀한 단어를 예측할 수 있다. 하지만 계산 비용이 크다는 문제점이 있다.   \r\n","마찬가지로 중심 단어에 윈도우를 두고, 윈도우 내의 주변 단어의 임베딩 벡터를 예측한다."]},{"cell_type":"code","metadata":{"id":"KtaRNtZHpyTa","executionInfo":{"status":"ok","timestamp":1610757927573,"user_tz":-540,"elapsed":706,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["model = Word2Vec(sentences=tokenList, size=100, window=5, min_count=1, workers=4, sg=1)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtmmTwZpp1ib","executionInfo":{"status":"ok","timestamp":1610757929213,"user_tz":-540,"elapsed":647,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"64520c33-aa52-4507-ef20-de264c43b0eb"},"source":["model_result = model.wv.most_similar(\"어린아이\")\r\n","model_result"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('통하', 0.23564516007900238),\n"," ('생명', 0.19320984184741974),\n"," ('보', 0.17897485196590424),\n"," ('정부', 0.17392389476299286),\n"," ('체계', 0.17053207755088806),\n"," ('담당', 0.15819336473941803),\n"," ('진상', 0.15100786089897156),\n"," ('지난해', 0.15062189102172852),\n"," ('사건', 0.1415776014328003),\n"," ('오늘', 0.13254183530807495)]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"e7eVY5Y4qaCK"},"source":["기사 본문 내용이 짧기 때문에, 모델을 학습하기에 corpus의 크기가 작다.  \r\n","유사도 또한 상당히 낮다.   \r\n","아래는 수집한 기사 87건들을 통해 corpus를 구성하고, Word2Vec 모델을 구축하는 내용이다."]},{"cell_type":"code","metadata":{"id":"ctw7JjHbz4GL","executionInfo":{"status":"ok","timestamp":1610762180507,"user_tz":-540,"elapsed":758,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["media_list = os.listdir(ORIGIN_PATH)\r\n","\r\n","result = []\r\n","forCount = []\r\n","for media in media_list:\r\n","    media_path = os.path.join(PREPROCESSED_PATH, media)\r\n","    article_list= os.listdir(media_path)\r\n","\r\n","    for article in article_list:\r\n","        reader = RawTextReader(os.path.join(media_path, article)) \r\n","        content = list(filter(None, reader))\r\n","        forCount += [token for sent in content for token in sent.split()]\r\n","        result += [sent.split() for sent in content]"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umuAT0mW1dDG","executionInfo":{"status":"ok","timestamp":1610762182125,"user_tz":-540,"elapsed":798,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"be8034e2-409a-4494-94ff-f6f0cb67679e"},"source":["print(\"전체 token의 개수 : {len}\".format(len=len(forCount)))\r\n","print(\"중복되지 않은 token의 개수 : {len}\".format(len=len(list(set(forCount)))))"],"execution_count":77,"outputs":[{"output_type":"stream","text":["전체 token의 개수 : 15668\n","중복되지 않은 token의 개수 : 2877\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hS3lk_yu1NiU","executionInfo":{"status":"ok","timestamp":1610762186522,"user_tz":-540,"elapsed":1793,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}}},"source":["model = Word2Vec(sentences=result, size=200, window=5, min_count=1, workers=4, sg=1)"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNcMcAjd1HA7","executionInfo":{"status":"ok","timestamp":1610762202780,"user_tz":-540,"elapsed":715,"user":{"displayName":"김수빈","photoUrl":"","userId":"17754099482493494628"}},"outputId":"e377b3d2-d21a-44f2-d2d8-a311ce6fa725"},"source":["model_result = model.wv.most_similar(\"어린아이\")\r\n","model_result"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('생명', 0.9995765089988708),\n"," ('당하', 0.9995399713516235),\n"," ('아이', 0.9995397329330444),\n"," ('대하', 0.9995381832122803),\n"," ('피해', 0.9995024800300598),\n"," ('사죄', 0.9994626641273499),\n"," ('어리', 0.999458909034729),\n"," ('관리', 0.9994567632675171),\n"," ('보', 0.9994520545005798),\n"," ('말씀', 0.9994302988052368)]"]},"metadata":{"tags":[]},"execution_count":80}]}]}