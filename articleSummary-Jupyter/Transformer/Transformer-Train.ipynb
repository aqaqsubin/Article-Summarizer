{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I9_qYGCjav47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from RC_Transformer.ipynb\n",
      "importing Jupyter notebook from /data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer/CommonModule/Handle_Dir.ipynb\n",
      "importing Jupyter notebook from /data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer/CommonModule/Encoder.ipynb\n",
      "importing Jupyter notebook from /data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer/CommonModule/Decoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Transformer import transformer\n",
    "from Transformer import CustomSchedule\n",
    "from CommonModule.Handle_Dir import mkdir_p, del_folder\n",
    "from CommonModule.Encoder import IntegerEncoder\n",
    "from CommonModule.Decoder import Decoder\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import iglob\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gaHSYvW2a0qq"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "SRC_BASE_DIR = os.path.join(BASE_DIR, 'TestSampleDir')\n",
    "\n",
    "VAL_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Valid-Preprocessed-Data\")\n",
    "VAL_SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Valid-Summary-Preprocessed-Data\")\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "\n",
    "PREDICT_PATH = os.path.join(DATA_BASE_DIR,\"Predict-Data\")\n",
    "\n",
    "WORD_ENCODING_DIR = os.path.join(os.path.join(SRC_BASE_DIR, 'articleSummary-Jupyter'), 'Word-Encoding-Model')\n",
    "MODEL_DIR = os.path.join(os.path.join(SRC_BASE_DIR, 'articleSummary-Jupyter'), 'Transformer-Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IdfXolhfa0ud"
   },
   "outputs": [],
   "source": [
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FEh5B1Ua0ys",
    "outputId": "fa4bbfa9-5ef0-456a-8bc8-6e91f13b0952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "model_num = len(list(iglob(os.path.join(WORD_ENCODING_DIR, 'spm-input-*.vocab'), recursive=False))) -1\n",
    "sp.Load(os.path.join(WORD_ENCODING_DIR, 'spm-input-{}.model').format(model_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5PziRMisa00c"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-reZP-XGa02O"
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    'model-type' : 'Sentence-Piece',\n",
    "    'inv_wv' : None,\n",
    "    'corpus' : None,\n",
    "    'spm' : sp\n",
    "}\n",
    "input_encoded_list = IntegerEncoder(options=options, filepaths=list(iglob(os.path.join(PREPROCESSED_PATH, '**.csv'), recursive=False))).encoder()\n",
    "output_encoded_list = IntegerEncoder(options=options, filepaths=list(iglob(os.path.join(SUMMARY_PREPROCESSED_PATH, '**.csv'), recursive=False))).encoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4BbwAz_da04P"
   },
   "outputs": [],
   "source": [
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 5000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = [sp.bos_id()]\n",
    "END_TOKEN = [sp.eos_id()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGsTrqfca7vH",
    "outputId": "5ff0e8ca-cc01-4df9-fba9-e351376a063d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_length = lambda x : np.max([len(line) for line in x])\n",
    "\n",
    "MAX_LEN = get_max_length(input_encoded_list)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUMMARY_MAX_LEN = get_max_length(output_encoded_list)\n",
    "SUMMARY_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_list = list(map(lambda list_ : START_TOKEN + list_ + END_TOKEN, input_encoded_list))\n",
    "output_encoded_list = list(map(lambda list_ : START_TOKEN + list_ + END_TOKEN, output_encoded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, output_train, output_test = train_test_split(\n",
    "    input_encoded_list, output_encoded_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_MAX_LEN +=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xknyLdoqa7xn"
   },
   "outputs": [],
   "source": [
    "# Padding\n",
    "train_input_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    input_train, maxlen=MAX_LEN, padding='post')\n",
    "train_summary_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    output_train, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "test_input_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    input_test, maxlen=MAX_LEN, padding='post')\n",
    "test_summary_encoded_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    output_test, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Uz60H9Xa7zh",
    "outputId": "94f586f1-1e32-401b-ab5a-91871c02014e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Contents Shape : (22658, 252)\n",
      "Train Summaries Shape : (22658, 252)\n",
      "Test Contents Shape : (5665, 252)\n",
      "Test Summaries Shape : (5665, 252)\n"
     ]
    }
   ],
   "source": [
    "print('Train Contents Shape : {}'.format(train_input_encoded_matrix.shape))\n",
    "print('Train Summaries Shape : {}'.format(train_summary_encoded_matrix.shape))\n",
    "print('Test Contents Shape : {}'.format(test_input_encoded_matrix.shape))\n",
    "print('Test Summaries Shape : {}'.format(test_summary_encoded_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KyZb5RcIa71h"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': train_input_encoded_matrix, # Encoder Input\n",
    "        'dec_inputs': train_summary_encoded_matrix[:, :-1] # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'outputs': train_summary_encoded_matrix[:, 1:]  \n",
    "    },\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PDUbZ_hCa73Z"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': test_input_encoded_matrix, # Encoder Input\n",
    "        'dec_inputs': test_summary_encoded_matrix[:, :-1] # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'outputs': test_summary_encoded_matrix[:, 1:]  \n",
    "    },\n",
    "))\n",
    "val_dataset = val_dataset.cache()\n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3TQ9HhRHbAUE"
   },
   "outputs": [],
   "source": [
    "lrate_scheduler = CustomSchedule(d_model=D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pwGjlRRAbAYV"
   },
   "outputs": [],
   "source": [
    "beta_1 = 0.9  \n",
    "beta_2 = 0.98\n",
    "epsilon = 10 ** -9\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lrate_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oI-wMmhkbAa4",
    "outputId": "78cb59ef-be68-47dc-9cb8-f260136f8a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 128)\n",
      "(None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU'):\n",
    "    model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=LAYER_NUM,\n",
    "        dff=DFF,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kw2DbMUNbAd7"
   },
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LEN-1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "y_NN8VXSeRTi"
   },
   "outputs": [],
   "source": [
    "checkpoint_dirpath = os.path.join(MODEL_DIR, \"RC_Transformer\")\n",
    "\n",
    "mkdir_p(checkpoint_dirpath)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_dirpath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wqg_m9NLbH2_",
    "outputId": "108d397d-ac84-411d-c905-f8beb794b331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    8960000     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, None, 128)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_1 (Position (None, None, 128)    0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 128)    0           positional_encoding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, None, 128)    231040      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 128)    17024       sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 128)    66816       sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, None, 128)    116608      sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, None, 384)    0           sequential[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, None, 128)    49280       tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 128)    10149632    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, None, 128)    0           sequential_4[0][0]               \n",
      "                                                                 sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 128)    10646656    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 70000)  9030000     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 39,267,056\n",
      "Trainable params: 39,265,520\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAYKWocIbH5J",
    "outputId": "61a312ae-46fa-4fa0-d325-3ac3ae4debdb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "\n",
    "model.fit(dataset, batch_size=BATCH_SIZE, epochs=30, verbose=2, validation_data=val_dataset, \n",
    "          shuffle=True, callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option={\n",
    "        'model-type' : 'Sentence-Piece',\n",
    "        'inv_wv' : None,\n",
    "        'corpus' : None,\n",
    "        'spm' : sp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(content, max_len):\n",
    "    \n",
    "#     enc_input_sent = IntegerEncoder(options=src_option, filepaths=None).line_encoder(content)\n",
    "#     enc_input_sent = START_TOKEN + enc_input_sent + END_TOKEN\n",
    "    enc_input_sent= content\n",
    "    enc_input_sent = tf.expand_dims(enc_input_sent, axis=0)\n",
    "    \n",
    "    output = START_TOKEN\n",
    "    output = tf.expand_dims(output, axis=0)\n",
    "            \n",
    "    for i in range(max_len):\n",
    "        predictions = model(inputs=[enc_input_sent, output], training=False)\n",
    "        \n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        predicted_id = tf.squeeze(predicted_id)\n",
    "\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], axis=0)], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(content):\n",
    "    prediction = evaluate(content, SUMMARY_MAX_LEN)\n",
    "\n",
    "    predict_list = prediction.numpy().tolist()\n",
    "    decoder = Decoder(option)\n",
    "    predicted_sentence = decoder.decode(predict_list)\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSVFile(baseDir, media, article_dist):\n",
    "    save_path = os.path.join(baseDir, media) + \".csv\"\n",
    "\n",
    "    article_dist.to_csv(save_path, mode='w', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_name(filepath):\n",
    "    filename = filepath.split(os.sep)[-1]\n",
    "    return filename.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_folder(PREDICT_PATH)\n",
    "mkdir_p(PREDICT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src data (기사 본문과 비교)\n",
    "\n",
    "#### ROUGE-L Score  \n",
    "reference : 기사 본문  \n",
    "produced summary : RC-Transformer 생성 요약문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "\n",
    "generated_summary_dist = pd.DataFrame(columns=['Origin Contents', 'Generated Summary', \n",
    "                                            'ROUGE-F1', 'ROUGE-Recall', 'ROUGE-Precision',\n",
    "                                              'ROUGE-F1-with-Target', 'ROUGE-Recall-with-Target', 'ROUGE-Precision-with-Target'])\n",
    "\n",
    "for inp, outp in zip(input_test, output_test):\n",
    "    decoder_src = Decoder(option)\n",
    "    input_sent = decoder_src.decode(inp)\n",
    "    target_sent = decoder_src.decode(outp)\n",
    "    \n",
    "    predict_summary = predict(inp)\n",
    "    \n",
    "    print('Input: {}'.format(input_sent))\n",
    "    print('Target : {}'.format(target_sent))\n",
    "    print('Output: {}'.format(predict_summary))\n",
    "    \n",
    "    # ROUGE-L Score\n",
    "    rouge_scores = rouge.get_scores(predict_summary, input_sent)\n",
    "    rouge_f = rouge_scores[0]['rouge-l']['f']\n",
    "    print('Rouge F1: {}'.format(rouge_f * 100))\n",
    "    \n",
    "    rouge_r = rouge_scores[0]['rouge-l']['r']\n",
    "    print('Rouge Recall: {}'.format(rouge_r * 100))\n",
    "    \n",
    "    rouge_p = rouge_scores[0]['rouge-l']['p']\n",
    "    print('Rouge Precision: {}\\n'.format(rouge_p * 100))\n",
    "    \n",
    "    \n",
    "    rouge_scores_with_target = rouge.get_scores(target_sent, input_sent)\n",
    "    tar_rouge_f = rouge_scores_with_target[0]['rouge-l']['f']\n",
    "    print('Rouge F1: {}'.format(tar_rouge_f * 100))\n",
    "    \n",
    "    tar_rouge_r = rouge_scores_with_target[0]['rouge-l']['r']\n",
    "    print('Rouge Recall: {}'.format(tar_rouge_r * 100))\n",
    "    \n",
    "    tar_rouge_p = rouge_scores_with_target[0]['rouge-l']['p']\n",
    "    print('Rouge Precision: {}\\n'.format(tar_rouge_p * 100))\n",
    "    \n",
    "    summary = {'Origin Contents' : input_sent, 'Generated Summary' : predict_summary,\n",
    "               'ROUGE-F1': rouge_f, 'ROUGE-Recall': rouge_r, 'ROUGE-Precision': rouge_p, \n",
    "               'ROUGE-F1-with-Target': tar_rouge_f, 'ROUGE-Recall-with-Target': tar_rouge_r, 'ROUGE-Precision-with-Target': tar_rouge_p}\n",
    "    \n",
    "    generated_summary_dist = generated_summary_dist.append(summary, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target data (추출 요약문과 비교)\n",
    "\n",
    "#### ROUGE-L Score  \n",
    "reference : gensim summarize 라이브러리를 이용해 추출한 추출 요약문    \n",
    "produced summary : RC-Transformer 생성 요약문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "generated_summary_target_dist = pd.DataFrame(columns=['Origin Contents', 'Target Summary', 'Generated Summary', \n",
    "                                                'ROUGE F1', 'ROUGE Recall', 'ROUGE Precision'])\n",
    "for inp, outp in zip(input_test, output_test):\n",
    "    decoder_src = Decoder(option)\n",
    "    input_sent = decoder_src.decode(inp)\n",
    "    target_sent = decoder_src.decode(outp)\n",
    "    \n",
    "    predict_summary = predict(inp)\n",
    "    \n",
    "    print('Input : {}'.format(input_sent))\n",
    "    print('Target : {}'.format(target_sent))\n",
    "    print('Output : {}'.format(predict_summary))\n",
    "    \n",
    "    rouge_scores = rouge.get_scores(predict_summary, target_sent)\n",
    "    rouge_f = rouge_scores[0]['rouge-l']['f']\n",
    "    print('Rouge F1: {}'.format(rouge_f * 100))\n",
    "    \n",
    "    rouge_r = rouge_scores[0]['rouge-l']['r']\n",
    "    print('Rouge Recall: {}'.format(rouge_r * 100))\n",
    "    \n",
    "    rouge_p = rouge_scores[0]['rouge-l']['p']\n",
    "    print('Rouge Precision: {}\\n'.format(rouge_p * 100))\n",
    "    \n",
    "    summary = {'Origin Contents' : input_sent, 'Target Summary' : target_sent,'Generated Summary' : predict_summary,\n",
    "               'ROUGE F1': rouge_f, 'ROUGE Recall': rouge_r, 'ROUGE Precision': rouge_p}\n",
    "    \n",
    "    generated_summary_target_dist = generated_summary_target_dist.append(summary, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "\n",
    "validation_generated_dist = pd.DataFrame(columns=['Origin Contents', 'Generated Summary', \n",
    "                                            'ROUGE F1', 'ROUGE Recall', 'ROUGE Precision'])\n",
    "\n",
    "for _, val_proc_path in enumerate(iglob(os.path.join(VAL_PREPROCESSED_PATH, '**.csv'), recursive=False)):\n",
    "\n",
    "    media_name = get_media_name(val_proc_path)\n",
    "    val_summary_path = os.path.join(VAL_SUMMARY_PREPROCESSED_PATH, media_name +\".csv\")\n",
    "    print(media_name, val_proc_path)\n",
    "    \n",
    "    f_src = open(val_proc_path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "    f_tar = open(val_summary_path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "        \n",
    "    for [_, title, contents], [_, _, target] in zip(csv.reader(f_src), csv.reader(f_tar)):\n",
    "        content = contents.split(\"\\t\")\n",
    "        target_summary = target.split(\"\\t\")\n",
    "        \n",
    "        encoder = IntergerEncoder(options=option, filepaths=None)\n",
    "        \n",
    "        input_sent = ' '.join(content)\n",
    "        input_enc_sent = START_TOKEN + encoder.line_encoder(content_line) + END_TOKEN\n",
    "        \n",
    "        predict_summary = predict(input_enc_sent)\n",
    "        target_summary = ' '.join(target_summary)\n",
    "    \n",
    "        print('Input: {}'.format(input_sent))\n",
    "        print('Output: {}'.format(predict_summary))\n",
    "    \n",
    "        rouge_scores = rouge.get_scores(predict_summary, input_sent)\n",
    "        rouge_f = rouge_scores[0]['rouge-l']['f']\n",
    "        print('Rouge F1: {}'.format(rouge_f * 100))\n",
    "    \n",
    "        rouge_r = rouge_scores[0]['rouge-l']['r']\n",
    "        print('Rouge Recall: {}'.format(rouge_r * 100))\n",
    "    \n",
    "        rouge_p = rouge_scores[0]['rouge-l']['p']\n",
    "        print('Rouge Precision: {}\\n'.format(rouge_p * 100))\n",
    "    \n",
    "        summary = {'Origin Contents' : input_sent, 'Generated Summary' : predict_summary,\n",
    "               'ROUGE F1': rouge_f, 'ROUGE Recall': rouge_r, 'ROUGE Precision': rouge_p}\n",
    "    \n",
    "        validation_generated_dist = validation_generated_dist.append(summary, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveCSVFile(PREDICT_PATH, 'KBS', generated_summary_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveCSVFile(PREDICT_PATH, 'KBS', generated_summary_target_dist)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RC_Transformer_Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
