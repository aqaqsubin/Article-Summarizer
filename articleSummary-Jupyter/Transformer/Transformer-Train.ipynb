{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Setting -> GPU 1번 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델의 구성 -> Transformer_Implement.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Transformer_Implement.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import Transformer_Implement as ti\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/TestDir\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "MINI_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Preprocessed-Data\")\n",
    "\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "MINI_SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Summary-Preprocessed-Data\")\n",
    "\n",
    "MODEL_BASE_DIR = os.path.join(os.path.join(BASE_DIR, 'articleSummary-Jupyter'), 'Word-Embedding')\n",
    "glove_model_path = os.path.join(MODEL_BASE_DIR, 'glove.model')\n",
    "corpus_model_path = os.path.join(MODEL_BASE_DIR, 'corpus.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def del_folder(path):\n",
    "    from shutil import rmtree\n",
    "    try:\n",
    "        rmtree(path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_switched_root_dir(path, save_root_dir):\n",
    "    path_token = path.split(os.sep)\n",
    "    path_token[4] = save_root_dir.split(os.sep)[4]\n",
    "    save_dir_path = os.sep.join(path_token[:6])\n",
    "    \n",
    "    return save_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCopier:\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = f.readlines()\n",
    "\n",
    "    def copy_article(self, save_dir):\n",
    "        mkdir_p(save_dir)\n",
    "        article_name = str(len(os.listdir(save_dir)))+\".txt\"\n",
    "\n",
    "        with open(os.path.join(save_dir, article_name), 'w', encoding='utf-8') as new_f:\n",
    "            new_f.writelines(self.lines)\n",
    "\n",
    "def load_proc_data(summary_path):\n",
    "\n",
    "    media_list = sorted(os.listdir(summary_path))\n",
    "        \n",
    "    for media_name in media_list:\n",
    "    \n",
    "        media_path = os.path.join(summary_path, media_name)\n",
    "        article_list = os.listdir(media_path)\n",
    "            \n",
    "        article_path_list = [os.path.join(media_path, article_name) for article_name in article_list]\n",
    "        \n",
    "        origin_root = PREPROCESSED_PATH\n",
    "        new_root = MINI_PREPROCESSED_PATH\n",
    "        \n",
    "        origin_proc_path_list = [os.path.join(get_switched_root_dir(path, origin_root), path.split(os.sep)[-1]) for path in article_path_list]\n",
    "        new_proc_path_list = [get_switched_root_dir(path, new_root) for path in article_path_list]\n",
    "\n",
    "        for origin_path, new_path in zip(origin_proc_path_list, new_proc_path_list):\n",
    "            article = ArticleCopier(origin_path)\n",
    "            article.copy_article(new_path)\n",
    "        map(lambda article : article.copy_article, new_proc_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del_folder(MINI_PREPROCESSED_PATH)\n",
    "#MINI_PREPROCESSED_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_proc_data(MINI_SUMMARY_PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치와 함께 임베딩 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Glove.load(glove_model_path)\n",
    "corpus = Corpus.load(corpus_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawTextReader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile(\"/n\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in ch:\n",
    "                yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegerEncoder:\n",
    "    def __init__(self, filepath, corpus):\n",
    "        self.filepath = filepath\n",
    "        self.corpus = corpus\n",
    "    \n",
    "    def get_encoded_vec_matrix(self):\n",
    "        media_list = os.listdir(self.filepath)\n",
    "        \n",
    "        encoded_vec_list = []\n",
    "        for media_name in media_list:\n",
    "    \n",
    "            media_path = os.path.join(self.filepath, media_name)\n",
    "            article_list = os.listdir(media_path)\n",
    "            \n",
    "            for article_name in article_list:\n",
    "                \n",
    "                reader = RawTextReader(os.path.join(media_path, article_name)) \n",
    "                content = list(filter(None, reader))\n",
    "                vec = np.array([corpus.dictionary[token] for sent in content for token in sent.split() if token in corpus.dictionary])\n",
    "                \n",
    "                encoded_vec_list.append(vec)\n",
    "\n",
    "        return np.array(encoded_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "VOCAB_SIZE = len(corpus.dictionary)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [VOCAB_SIZE], [VOCAB_SIZE + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> Token : [65848]\n",
      "<EOS> Token : [65849]\n",
      "Vocabulary Size : 65850\n"
     ]
    }
   ],
   "source": [
    "print('<SOS> Token : {}'.format(START_TOKEN))\n",
    "print('<EOS> Token : {}'.format(END_TOKEN))\n",
    "\n",
    "VOCAB_SIZE += 2\n",
    "print('Vocabulary Size : {}'.format(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 된 99,237개의 기사 본문 데이터에 정수 인코딩을 수행한다.  \n",
    "\n",
    "정수 인코딩 수행 후에 (99237, None)의 크기를 가지는 Matrix가 되며,   \n",
    "각 인코딩된 값을 임베딩 벡터 값으로 대체한 후에는 (99237, `max_token`, 256)의 크기를 가지는 Tensor가 된다.  \n",
    "- `max_token`은 각 기사 본문의 토큰 수 중 가장 큰 값을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59604,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoder = IntegerEncoder(MINI_PREPROCESSED_PATH, corpus)\n",
    "train_encoded_matrix = train_encoder.get_encoded_vec_matrix()\n",
    "train_encoded_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_length = lambda x : np.max([len(x[idx]) for idx in range(len(x))])\n",
    "MAX_LEN = get_max_length(train_encoded_matrix)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59604,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder = IntegerEncoder(MINI_SUMMARY_PREPROCESSED_PATH, corpus)\n",
    "target_encoded_matrix = target_encoder.get_encoded_vec_matrix()\n",
    "target_encoded_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_max_len = get_max_length(target_encoded_matrix)\n",
    "MAX_LEN = target_max_len if target_max_len > MAX_LEN else MAX_LEN\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_padding(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (content, summary) in zip(inputs, outputs):\n",
    "        # Add Start Token, End Token\n",
    "        content = START_TOKEN + content + END_TOKEN\n",
    "        summary = START_TOKEN + summary + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(content)\n",
    "        tokenized_outputs.append(summary)\n",
    "\n",
    "    # Padding\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LEN, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LEN, padding='post')\n",
    "        \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents Shape : (59604, 4392)\n",
      "Summaries Shape : (59604, 4392)\n"
     ]
    }
   ],
   "source": [
    "contents, summaries = encode_and_padding(train_encoded_matrix, target_encoded_matrix)\n",
    "\n",
    "print('Contents Shape : {}'.format(contents.shape))\n",
    "print('Summaries Shape : {}'.format(summaries.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_vector(int_enc_vec):\n",
    "    return np.array([glove.word_vectors[integer] for integer in int_enc_vec])\n",
    "\n",
    "def embedding_matrix(int_enc_matrix):\n",
    "    row_list = []\n",
    "    for idx, row_vec in enumerate(int_enc_matrix):\n",
    "        emb_Vec = embedding_vector(row_vec)\n",
    "        row_list.append(emb_Vec)\n",
    "    return row_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = embedding_matrix(train_encoded_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'encoder_inputs': contents, # Encoder Input\n",
    "        'decoder_inputs': summaries[:, :-1] # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'Output': summaries[:, 1:]  \n",
    "    },\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate_scheduler = ti.LearningRate(d_model=D_MODEL, warmup_steps=WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9  \n",
    "beta_2 = 0.98\n",
    "epsilon = 10 ** -9\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lrate_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Encoding (65850, 256)\n",
      "encoder_layer_0 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_0 sub-layer 2\n",
      "encoder_layer_1 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_1 sub-layer 2\n",
      "encoder_layer_2 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_2 sub-layer 2\n",
      "encoder_layer_3 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_3 sub-layer 2\n",
      "encoder_layer_4 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_4 sub-layer 2\n",
      "encoder_layer_5 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "encoder_layer_5 sub-layer 2\n",
      "Positional Encoding (65850, 256)\n",
      "decoder_layer_0 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_0 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_0 sub-layer 3\n",
      "decoder_layer_1 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_1 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_1 sub-layer 3\n",
      "decoder_layer_2 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_2 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_2 sub-layer 3\n",
      "decoder_layer_3 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_3 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_3 sub-layer 3\n",
      "decoder_layer_4 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_4 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_4 sub-layer 3\n",
      "decoder_layer_5 sub-layer 1\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_5 sub-layer 2\n",
      "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
      "\n",
      "decoder_layer_5 sub-layer 3\n"
     ]
    }
   ],
   "source": [
    "model = ti.Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    layer_num=LAYER_NUM,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS).get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 256)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None, 256)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (Functional)            (None, 65850, 256)   3162624     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (Functional)            (None, 65850, 256)   4744704     decoder_inputs[0][0]             \n",
      "                                                                 Encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 65850, 65850) 16923450    Decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,830,778\n",
      "Trainable params: 24,830,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer Transformer expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 4392) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-80378a6b5eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer Transformer expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 4392) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "\n",
    "model.fit(x=contents, y=summaries, batch_size=16, epochs=EPOCHS, shuffle=True, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
