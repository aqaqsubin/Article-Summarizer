{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Transformer_Implement import Transformer, LearningRate\n",
    "from CommonModule.Handle_Dir import mkdir_p, del_folder\n",
    "from CommonModule.Embedding import Embedding\n",
    "from CommonModule.Encoder import Encoder\n",
    "from CommonModule.Decoder import Decoder\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "import tensorflow as tf\n",
    "from glove import Corpus, Glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb/TestSampleDir\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'articles')\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "PREDICT_PATH = os.path.join(DATA_BASE_DIR,\"Predict-Data\")\n",
    "\n",
    "WORD_EMBEDDING_DIR = os.path.join(os.path.join(BASE_DIR, 'articleSummary-Jupyter'), 'Word-Embedding-Model')\n",
    "MODEL_DIR = os.path.join(os.path.join(BASE_DIR, 'articleSummary-Jupyter'), 'Transformer-Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 128\n",
    "MIN_COUNT = 10\n",
    "\n",
    "SUMMARY_MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model_path = os.path.join(WORD_EMBEDDING_DIR, 'glove-{d_model}-{mincount}.model'.format(d_model=D_MODEL, mincount=MIN_COUNT))\n",
    "corpus_model_path = os.path.join(WORD_EMBEDDING_DIR, 'input-corpus-{d_model}-{mincount}.model'.format(d_model=D_MODEL, mincount=MIN_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Glove.load(glove_model_path)\n",
    "corpus = Corpus.load(corpus_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = ['<SOS>']\n",
    "END_TOKEN = ['<EOS>']\n",
    "\n",
    "START_TOKEN_NUM = corpus.dictionary[START_TOKEN[0]]\n",
    "END_TOKEN_NUM = corpus.dictionary[END_TOKEN[0]]\n",
    "\n",
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "VOCAB_SIZE = len(corpus.dictionary)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 5000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 58112, 128)\n",
      "encoder_layer_0 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_0 sub-layer 2\n",
      "encoder_layer_1 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_1 sub-layer 2\n",
      "encoder_layer_2 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_2 sub-layer 2\n",
      "encoder_layer_3 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_3 sub-layer 2\n",
      "encoder_layer_4 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_4 sub-layer 2\n",
      "encoder_layer_5 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "encoder_layer_5 sub-layer 2\n",
      "(1, 58112, 128)\n",
      "decoder_layer_0 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_0 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_0 sub-layer 3\n",
      "decoder_layer_1 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_1 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_1 sub-layer 3\n",
      "decoder_layer_2 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_2 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_2 sub-layer 3\n",
      "decoder_layer_3 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_3 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_3 sub-layer 3\n",
      "decoder_layer_4 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_4 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_4 sub-layer 3\n",
      "decoder_layer_5 sub-layer 1\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_5 sub-layer 2\n",
      "[Input] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Dense] Q shape : (None, None, 128), K shape : (None, None, 128), V shape : (None, None, 128)\n",
      "\n",
      "[Splited] Q shape : (None, 8, None, 16), K shape : (None, 8, None, 16), V shape : (None, 8, None, 16)\n",
      "\n",
      "decoder_layer_5 sub-layer 3\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = Transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        layer_num=LAYER_NUM,\n",
    "        dff=DFF,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout = 0.3).get_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ksb/TestSampleDir/articleSummary-Jupyter/Transformer-Model/model-checkpoint-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f98283ec9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_num = len(list(iglob(os.path.join(MODEL_DIR, '*.index'), recursive=False))) - 1\n",
    "checkpoint_path = os.path.join(MODEL_DIR, 'model-checkpoint-{}'.format(checkpoint_num))\n",
    "print(checkpoint_path)\n",
    "\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokens, max_len):\n",
    "    \n",
    "    enc_input_sent = START_TOKEN + tokens+ END_TOKEN\n",
    "    enc_input_sent = Embedding(corpus=corpus, glove=glove, model='GloVe').get_embedded_list(enc_input_sent)\n",
    "    enc_input_sent = tf.expand_dims(enc_input_sent, axis=0)\n",
    "    \n",
    "    dec_input_sent = START_TOKEN\n",
    "    dec_input_sent = Embedding(corpus=corpus, glove=glove, model='GloVe').get_embedded_list(dec_input_sent)\n",
    "    dec_input_sent = tf.expand_dims(dec_input_sent, axis=0)\n",
    "    \n",
    "    output = tf.expand_dims([START_TOKEN_NUM], axis=0)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        predictions = model(inputs=[enc_input_sent, dec_input_sent], training=False)\n",
    "\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        predicted_id = tf.squeeze(predicted_id)\n",
    "        print(\"index : {idx}, predicted : {pre}\".format(idx=i, pre=predicted_id))\n",
    "        \n",
    "        predicted_emb = [glove.word_vectors[predicted_id]]\n",
    "        predicted_emb = tf.expand_dims(predicted_emb, axis=0)\n",
    "\n",
    "        if tf.equal(predicted_id, END_TOKEN_NUM):\n",
    "            break\n",
    "\n",
    "        dec_input_sent = tf.concat([dec_input_sent, predicted_emb], axis=1)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], axis=0)], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokens):\n",
    "    prediction = evaluate(tokens, SUMMARY_MAX_LEN)\n",
    "\n",
    "    options = {\n",
    "        'model-type' : 'GloVe',\n",
    "        'inv_wv' : None,\n",
    "        'corpus' : corpus\n",
    "    }\n",
    "    decoder = Decoder(options)\n",
    "    predicted_sentence = decoder.decode(prediction.numpy())\n",
    "\n",
    "    print('Input: {}'.format(' '.join(tokens)))\n",
    "    print('Output: {}'.format(' '.join(predicted_sentence)))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSVFile(baseDir, media, article_dist):\n",
    "    save_path = os.path.join(baseDir, media) + \".csv\"\n",
    "\n",
    "    article_dist.to_csv(save_path, mode='w', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_name(filepath):\n",
    "    filename = filepath.split(os.sep)[-1]\n",
    "    return filename.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBS /data/ksb/TestSampleDir/articles/Preprocessed-Data/KBS.csv\n",
      "0 이태원 클럽발 확진자 계속 증가…각 지자체 추가 행정명령--0\n",
      "index : 0, predicted : 362\n",
      "index : 1, predicted : 362\n",
      "index : 2, predicted : 362\n",
      "index : 3, predicted : 362\n",
      "index : 4, predicted : 362\n",
      "index : 5, predicted : 362\n",
      "index : 6, predicted : 362\n",
      "index : 7, predicted : 362\n",
      "index : 8, predicted : 362\n",
      "index : 9, predicted : 362\n",
      "index : 10, predicted : 362\n",
      "index : 11, predicted : 362\n",
      "index : 12, predicted : 362\n",
      "index : 13, predicted : 362\n",
      "index : 14, predicted : 362\n",
      "index : 15, predicted : 362\n",
      "index : 16, predicted : 362\n",
      "index : 17, predicted : 362\n",
      "index : 18, predicted : 362\n",
      "index : 19, predicted : 362\n",
      "index : 20, predicted : 362\n",
      "index : 21, predicted : 362\n",
      "index : 22, predicted : 362\n",
      "index : 23, predicted : 362\n",
      "index : 24, predicted : 362\n",
      "index : 25, predicted : 362\n",
      "index : 26, predicted : 362\n",
      "index : 27, predicted : 362\n",
      "index : 28, predicted : 362\n",
      "index : 29, predicted : 362\n",
      "index : 30, predicted : 362\n",
      "index : 31, predicted : 362\n",
      "index : 32, predicted : 362\n",
      "index : 33, predicted : 362\n",
      "index : 34, predicted : 362\n",
      "index : 35, predicted : 362\n",
      "index : 36, predicted : 362\n",
      "index : 37, predicted : 362\n",
      "index : 38, predicted : 362\n",
      "index : 39, predicted : 362\n",
      "index : 40, predicted : 362\n",
      "index : 41, predicted : 362\n",
      "index : 42, predicted : 362\n",
      "index : 43, predicted : 362\n",
      "index : 44, predicted : 362\n",
      "index : 45, predicted : 362\n",
      "index : 46, predicted : 362\n",
      "index : 47, predicted : 362\n",
      "index : 48, predicted : 362\n",
      "index : 49, predicted : 362\n",
      "index : 50, predicted : 362\n",
      "index : 51, predicted : 362\n",
      "index : 52, predicted : 362\n",
      "index : 53, predicted : 362\n",
      "index : 54, predicted : 362\n",
      "index : 55, predicted : 362\n",
      "index : 56, predicted : 362\n",
      "index : 57, predicted : 362\n",
      "index : 58, predicted : 362\n",
      "index : 59, predicted : 362\n",
      "index : 60, predicted : 362\n",
      "index : 61, predicted : 362\n",
      "index : 62, predicted : 362\n",
      "index : 63, predicted : 362\n",
      "index : 64, predicted : 362\n",
      "index : 65, predicted : 362\n",
      "index : 66, predicted : 362\n",
      "index : 67, predicted : 362\n",
      "index : 68, predicted : 362\n",
      "index : 69, predicted : 362\n",
      "index : 70, predicted : 362\n",
      "index : 71, predicted : 362\n",
      "index : 72, predicted : 362\n",
      "index : 73, predicted : 362\n",
      "index : 74, predicted : 362\n",
      "index : 75, predicted : 362\n",
      "index : 76, predicted : 362\n",
      "index : 77, predicted : 362\n",
      "index : 78, predicted : 362\n",
      "index : 79, predicted : 362\n",
      "index : 80, predicted : 362\n",
      "index : 81, predicted : 362\n",
      "index : 82, predicted : 362\n",
      "index : 83, predicted : 362\n",
      "index : 84, predicted : 362\n",
      "index : 85, predicted : 362\n",
      "index : 86, predicted : 362\n",
      "index : 87, predicted : 362\n",
      "index : 88, predicted : 362\n",
      "index : 89, predicted : 362\n",
      "index : 90, predicted : 362\n",
      "index : 91, predicted : 362\n",
      "index : 92, predicted : 362\n",
      "index : 93, predicted : 362\n",
      "index : 94, predicted : 362\n",
      "index : 95, predicted : 362\n",
      "index : 96, predicted : 362\n",
      "index : 97, predicted : 362\n",
      "index : 98, predicted : 362\n",
      "index : 99, predicted : 362\n",
      "Input: 이태원 클럽 발 감염의 영향으로 코로나19 확진자가 계속 늘고 있습니다 지자체는 감염 확산을 막기 위해 유흥시설 집합금지 행정 명령을 추가로 내렸습니다 연결합니다 이태원 클럽 발 감염자 증가세가 좀처럼 꺾이지 않는 군요 어제 하루 코로나19 확진자가 29명 늘어 누적 확진자는 10 991명이 됐습니다 29명 가운데 20명이 이태원 클럽 관련 신규 확진자입니다 이태원 클럽 발 감염이 확산세를 보이는 가운데 3차 감염 의심 사례도 나왔습니다 서울 도봉구에서 지난 12일 확진 판정을 받은 10대 남성이 지난 7일 코인노래방을 방문한 뒤 증상이 나타났는데 이태원 클럽 확진자와 접촉한 감염자가 같은 시간대에 이곳을 방문했던 것으로 확인됐습니다 서울 서대문구와 마포구 주점에서도 확진자가 나왔습니다 이태원 클럽을 방문했다가 서대문구 주점을 찾은 외국인 3명과 비슷한 시기에 해당 주점을 방문한 20대 남성까지 4명이 확진 판정을 받았습니다 마포구 소재 주점에서는 지난 12일 첫 확진자가 나온 뒤 일행 4명이 추가 확진 판정을 받았습니다 교육당국과 지자체들도 대책 마련에 분주하겠군요 이태원 클럽 발 감염으로 학원 수강생들이 확진 판정을 받자 교육 당국은 방역 수칙을 지키지 않는 학원에 집합 금지 명령을 내리기로 했습니다\n",
      "Output: <SOS> 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면\n",
      "<SOS> 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면 따르면\n"
     ]
    }
   ],
   "source": [
    "del_folder(PREDICT_PATH)\n",
    "mkdir_p(PREDICT_PATH)\n",
    "\n",
    "generated_summary_dist = pd.DataFrame(columns=['Title', 'Contents'])\n",
    "\n",
    "for _, proc_path in enumerate(iglob(os.path.join(PREPROCESSED_PATH, '**.csv'), recursive=False)):\n",
    "    \n",
    "    media_name = get_media_name(proc_path)\n",
    "    print(media_name, proc_path)\n",
    "    \n",
    "    f = open(proc_path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "    \n",
    "    for [article_idx, title, contents] in csv.reader(f):\n",
    "        print(article_idx, title)\n",
    "        content = contents.split(\"\\t\")\n",
    "                \n",
    "        tokens = [token for sent in content for token in sent.split()]\n",
    "        predict_summary = ' '.join(predict(tokens))\n",
    "        print(predict_summary)\n",
    "        break\n",
    "        summary = {'Title' : title, 'Contents' : predict_summary}\n",
    "        generated_summary_dist = generated_summary_dist.append(summary, ignore_index=True)\n",
    "    \n",
    "    saveCSVFile(PREDICT_PATH, media_name, generated_summary_dist)\n",
    "    f.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
