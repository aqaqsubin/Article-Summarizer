{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Setting -> GPU 1번 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "if cpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(cpus[0], 'CPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델의 구성 -> Transformer_Implement.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /data/ksb/TestDir/articleSummary-Jupyter/Transformer/CommonModule/Handle_Dir.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import Transformer_Implement as ti\n",
    "from CommonModule.Handle_Dir import mkdir_p, del_folder\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb/TestDir\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "MINI_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Preprocessed-Data\")\n",
    "\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "MINI_SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Summary-Preprocessed-Data\")\n",
    "\n",
    "MODEL_BASE_DIR = os.path.join(Path(os.getcwd()).parent, 'Word-Embedding-Model')\n",
    "word2vec_model_path = os.path.join(MODEL_BASE_DIR, 'word2vec-256.model')\n",
    "wv_model_path = os.path.join(MODEL_BASE_DIR, 'word2vec-256.wordvectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치와 함께 임베딩 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(word2vec_model_path)\n",
    "wv = KeyedVectors.load(wv_model_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_list(filepath, wv):\n",
    "\n",
    "    embedding_vec_list = []\n",
    "    for idx, proc_path in enumerate(iglob(os.path.join(filepath, '**.csv'), recursive=False)):\n",
    "    \n",
    "        f = open(proc_path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "            \n",
    "        for [article_idx, title, contents] in csv.reader(f):  \n",
    "            content = contents.split(\"\\t\")    \n",
    "            vec = np.array([wv.word_vec(token) for sent in content for token in sent.split() if token in wv])\n",
    "            embedding_vec_list.append(vec)\n",
    "\n",
    "    return embedding_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "VOCAB_SIZE = wv.vectors.shape[0]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 된 59,604개의 기사 본문 데이터를 임베딩 벡터로 변환한다\n",
    "\n",
    "각 기사마다 토큰 개수에 따라 (None, 256)의 Matrix를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 기사의 토큰에 대해 임베딩을 수행한 결과 리스트를 `train_embedded_list`, `target_embedded_list`로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_list = get_embedded_list(MINI_PREPROCESSED_PATH, wv)\n",
    "target_embedded_list = get_embedded_list(MINI_SUMMARY_PREPROCESSED_PATH, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_length = lambda x : np.max([len(x[idx]) for idx in range(len(x))])\n",
    "MAX_LEN = get_max_length(train_embedded_list)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_max_len = get_max_length(target_embedded_list)\n",
    "MAX_LEN = target_max_len if target_max_len > MAX_LEN else MAX_LEN\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장의 토큰을 임베딩 벡터로 변환한다.  \n",
    "\n",
    "각 인코딩된 값을 임베딩 벡터 값으로 대체한 후에는 (59604, `max_token`, 256)의 크기를 가지는 Tensor가 된다.  \n",
    "- `max_token`은 각 기사 본문의 토큰 수 중 가장 큰 값을 의미한다.\n",
    "\n",
    "이의 결과로 (59604, 4392, 256)의 dimension을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_matrix = tf.keras.preprocessing.sequence.pad_sequences(train_embedded_list, maxlen=40, padding='post', dtype=np.float32)\n",
    "target_embedded_matrix = tf.keras.preprocessing.sequence.pad_sequences(target_embedded_list, maxlen=40, padding='post', dtype=np.float32)\n",
    "\n",
    "print(\"Train Embedded Matrix shape : {train} \\nTargetEmbedded Matrix shape : {target}\"\\\n",
    "      .format(train=train_embedded_matrix.shape,\n",
    "             target=target_embedded_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset` 구조  \n",
    "```\n",
    "({'encoder_inputs' : [[[...]]], 'decoder_inputs' : [[[...]]] }, { 'Output' : [[[...]]] }) 의 튜플이 59604개 있다.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = target_embedded_matrix\n",
    "decoder_inputs[:, -1, :] = 0.0\n",
    "\n",
    "outputs = target_embedded_matrix\n",
    "outputs[:, 1, :] = 0.0\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'encoder_inputs': train_embedded_matrix, # Encoder Input\n",
    "        'decoder_inputs': decoder_inputs # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'Output': outputs \n",
    "    },\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_1, dict_2 in dataset.as_numpy_iterator():\n",
    "    print(\"encoder input : {enc}, decoder input : {dec}\".format(enc= dict_1['encoder_inputs'].shape,\n",
    "                                                               dec=dict_1['decoder_inputs'].shape))\n",
    "    print(\"output shape : {}\".format(dict_2['Output'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 59604를 `BATCH_SIZE(=64)`에 따라 분할하며, \n",
    "dataset의 크기는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 메모리 또는 로컬 저장소에 캐시, 각 epoch 동안 실행되는 일부 작업(파일 열기 및 데이터 읽기 등)이 저장됨\n",
    "dataset = dataset.cache() \n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_1, dict_2 in dataset.as_numpy_iterator():    \n",
    "    print(\"encoder input : {enc}, decoder input : {dec}\".format(enc= dict_1['encoder_inputs'].shape,\n",
    "                                                               dec=dict_1['decoder_inputs'].shape))\n",
    "    print(\"output shape : {}\".format(dict_2['Output'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률 Learning Rate 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate_scheduler = ti.LearningRate(d_model=D_MODEL, warmup_steps=WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9  \n",
    "beta_2 = 0.98\n",
    "epsilon = 10 ** -9\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lrate_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = ti.Transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        layer_num=LAYER_NUM,\n",
    "        dff=DFF,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS).get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "\n",
    "model.fit(dataset, batch_size=16, epochs=EPOCHS, shuffle=True, callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
