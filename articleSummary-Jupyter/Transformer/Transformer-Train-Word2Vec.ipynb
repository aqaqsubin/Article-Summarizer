{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Setting -> GPU 1번 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "if cpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(cpus[0], 'CPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델의 구성 -> Transformer_Implement.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Transformer_Implement as ti\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb/TestDir\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "MINI_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Preprocessed-Data\")\n",
    "\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "MINI_SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Summary-Preprocessed-Data\")\n",
    "\n",
    "MODEL_BASE_DIR = os.path.join(Path(os.getcwd()).parent, 'Word-Embedding-Model')\n",
    "word2vec_model_path = os.path.join(MODEL_BASE_DIR, 'word2vec-256.model')\n",
    "wv_model_path = os.path.join(MODEL_BASE_DIR, 'word2vec-256.wordvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def del_folder(path):\n",
    "    from shutil import rmtree\n",
    "    try:\n",
    "        rmtree(path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_switched_root_dir(path, save_root_dir):\n",
    "    path_token = path.split(os.sep)\n",
    "    path_token[4] = save_root_dir.split(os.sep)[4]\n",
    "    save_dir_path = os.sep.join(path_token[:6])\n",
    "    \n",
    "    return save_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCopier:\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = f.readlines()\n",
    "\n",
    "    def copy_article(self, save_dir):\n",
    "        mkdir_p(save_dir)\n",
    "        article_name = str(len(os.listdir(save_dir)))+\".txt\"\n",
    "\n",
    "        with open(os.path.join(save_dir, article_name), 'w', encoding='utf-8') as new_f:\n",
    "            new_f.writelines(self.lines)\n",
    "\n",
    "def load_proc_data(summary_path):\n",
    "\n",
    "    media_list = sorted(os.listdir(summary_path))\n",
    "        \n",
    "    for media_name in media_list:\n",
    "    \n",
    "        media_path = os.path.join(summary_path, media_name)\n",
    "        article_list = os.listdir(media_path)\n",
    "            \n",
    "        article_path_list = [os.path.join(media_path, article_name) for article_name in article_list]\n",
    "        \n",
    "        origin_root = PREPROCESSED_PATH\n",
    "        new_root = MINI_PREPROCESSED_PATH\n",
    "        \n",
    "        origin_proc_path_list = [os.path.join(get_switched_root_dir(path, origin_root), path.split(os.sep)[-1]) for path in article_path_list]\n",
    "        new_proc_path_list = [get_switched_root_dir(path, new_root) for path in article_path_list]\n",
    "\n",
    "        for origin_path, new_path in zip(origin_proc_path_list, new_proc_path_list):\n",
    "            article = ArticleCopier(origin_path)\n",
    "            article.copy_article(new_path)\n",
    "        map(lambda article : article.copy_article, new_proc_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del_folder(MINI_PREPROCESSED_PATH)\n",
    "#MINI_PREPROCESSED_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_proc_data(MINI_SUMMARY_PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치와 함께 임베딩 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(word2vec_model_path)\n",
    "wv = KeyedVectors.load(wv_model_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawTextReader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile(\"/n\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in ch:\n",
    "                yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_list(filepath, wv):\n",
    "    media_list = os.listdir(filepath)\n",
    "    embedding_vec_list = []\n",
    "    for media_name in media_list:\n",
    "    \n",
    "        media_path = os.path.join(filepath, media_name)\n",
    "        article_list = os.listdir(media_path)\n",
    "            \n",
    "        for article_name in article_list:\n",
    "                \n",
    "            reader = RawTextReader(os.path.join(media_path, article_name)) \n",
    "            content = list(filter(None, reader))\n",
    "                \n",
    "            vec = np.array([wv.word_vec(token) for sent in content for token in sent.split() if token in wv])\n",
    "            embedding_vec_list.append(vec)\n",
    "\n",
    "    return embedding_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "VOCAB_SIZE = wv.vectors.shape[0]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 된 59,604개의 기사 본문 데이터를 임베딩 벡터로 변환한다\n",
    "\n",
    "각 기사마다 토큰 개수에 따라 (None, 256)의 Matrix를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 기사의 토큰에 대해 임베딩을 수행한 결과 리스트를 `train_embedded_list`, `target_embedded_list`로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_list = get_embedded_list(MINI_PREPROCESSED_PATH, wv)\n",
    "target_embedded_list = get_embedded_list(MINI_SUMMARY_PREPROCESSED_PATH, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_length = lambda x : np.max([len(x[idx]) for idx in range(len(x))])\n",
    "MAX_LEN = get_max_length(train_embedded_list)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_max_len = get_max_length(target_embedded_list)\n",
    "MAX_LEN = target_max_len if target_max_len > MAX_LEN else MAX_LEN\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장의 토큰을 임베딩 벡터로 변환한다.  \n",
    "\n",
    "각 인코딩된 값을 임베딩 벡터 값으로 대체한 후에는 (59604, `max_token`, 256)의 크기를 가지는 Tensor가 된다.  \n",
    "- `max_token`은 각 기사 본문의 토큰 수 중 가장 큰 값을 의미한다.\n",
    "\n",
    "이의 결과로 (59604, 4392, 256)의 dimension을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_matrix = tf.keras.preprocessing.sequence.pad_sequences(train_embedded_list, maxlen=40, padding='post', dtype=np.float32)\n",
    "target_embedded_matrix = tf.keras.preprocessing.sequence.pad_sequences(target_embedded_list, maxlen=40, padding='post', dtype=np.float32)\n",
    "\n",
    "print(\"Train Embedded Matrix shape : {train} \\nTargetEmbedded Matrix shape : {target}\"\\\n",
    "      .format(train=train_embedded_matrix.shape,\n",
    "             target=target_embedded_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset` 구조  \n",
    "```\n",
    "({'encoder_inputs' : [[[...]]], 'decoder_inputs' : [[[...]]] }, { 'Output' : [[[...]]] }) 의 튜플이 59604개 있다.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = target_embedded_matrix\n",
    "decoder_inputs[:, -1, :] = 0.0\n",
    "\n",
    "outputs = target_embedded_matrix\n",
    "outputs[:, 1, :] = 0.0\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'encoder_inputs': train_embedded_matrix, # Encoder Input\n",
    "        'decoder_inputs': decoder_inputs # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'Output': outputs \n",
    "    },\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_1, dict_2 in dataset.as_numpy_iterator():\n",
    "    print(\"encoder input : {enc}, decoder input : {dec}\".format(enc= dict_1['encoder_inputs'].shape,\n",
    "                                                               dec=dict_1['decoder_inputs'].shape))\n",
    "    print(\"output shape : {}\".format(dict_2['Output'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 59604를 `BATCH_SIZE(=64)`에 따라 분할하며, \n",
    "dataset의 크기는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 메모리 또는 로컬 저장소에 캐시, 각 epoch 동안 실행되는 일부 작업(파일 열기 및 데이터 읽기 등)이 저장됨\n",
    "dataset = dataset.cache() \n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_1, dict_2 in dataset.as_numpy_iterator():    \n",
    "    print(\"encoder input : {enc}, decoder input : {dec}\".format(enc= dict_1['encoder_inputs'].shape,\n",
    "                                                               dec=dict_1['decoder_inputs'].shape))\n",
    "    print(\"output shape : {}\".format(dict_2['Output'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률 Learning Rate 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate_scheduler = ti.LearningRate(d_model=D_MODEL, warmup_steps=WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9  \n",
    "beta_2 = 0.98\n",
    "epsilon = 10 ** -9\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lrate_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = ti.Transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        layer_num=LAYER_NUM,\n",
    "        dff=DFF,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS).get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "\n",
    "model.fit(dataset, batch_size=16, epochs=EPOCHS, shuffle=True, callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
