{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegerEncoder:\n",
    "    def __init__(self, filepaths, options):\n",
    "        self.filepaths = filepaths\n",
    "        \n",
    "        self.model = options['model-type']\n",
    "        self.inv_wv = options['inv_wv']\n",
    "        self.corpus = options['corpus']\n",
    "        self.sp = options['spm']\n",
    "    \n",
    "    def __get_token_matrix(self):\n",
    "        token_list =[]\n",
    "        \n",
    "        for path in self.filepaths:\n",
    "            f = open(path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "            \n",
    "            for [_, title, contents] in csv.reader(f):\n",
    "                content = contents.split(\"\\t\")\n",
    "                vec = [token for sent in content for token in sent.split()]\n",
    "\n",
    "                token_list.append(np.array(vec))\n",
    "                \n",
    "            f.close()\n",
    "\n",
    "        return token_list\n",
    "\n",
    "    def __get_line_list(self):\n",
    "        line_list =[]\n",
    "        \n",
    "        for path in self.filepaths:\n",
    "            f = open(path, 'r', newline=\"\\n\", encoding=\"utf-8\")\n",
    "            \n",
    "            for [_, title, contents] in csv.reader(f):\n",
    "                content = contents.split(\"\\t\")\n",
    "                line_list.append(' '.join(content))\n",
    "                \n",
    "            f.close()\n",
    "\n",
    "        return line_list\n",
    "    \n",
    "    def __glove_encoding(self, token_list):\n",
    "        return list(map(lambda line: [self.corpus.dictionary[token] for token in line \n",
    "                                      if token in self.corpus.dictionary], token_list))\n",
    "        \n",
    "    def __sentencepiece_encoding(self, token_list):\n",
    "        return list(map(lambda line: self.sp.EncodeAsIds(line), token_list))\n",
    "    \n",
    "    def __word2vec_encoding(self, token_list):\n",
    "        return list(map(lambda line: [self.inv_wv[token] for token in line\n",
    "                                     if token in self.inv_wv], token_list))  \n",
    "    \n",
    "    def encoder(self):\n",
    "\n",
    "        token_list = self.__get_token_matrix()\n",
    "        if self.model is 'GloVe':\n",
    "            encoding_vec_list = self.__glove_encoding(token_list) \n",
    "        elif self.model is 'Word2Vec' :\n",
    "            encoding_vec_list = self.__word2vec_encoding(token_list)\n",
    "        else:\n",
    "            encoding_vec_list = self.__sentencepiece_encoding(self.__get_line_list())\n",
    "        \n",
    "        return encoding_vec_list   \n",
    "    \n",
    "class Padding:\n",
    "    def __init__(self, max_len = None):\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def padding(self, vec_list):\n",
    "        vec_matrix = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            vec_list, maxlen=self.max_len, padding='post', value=\"\", dtype='str')\n",
    "        \n",
    "        return vec_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
