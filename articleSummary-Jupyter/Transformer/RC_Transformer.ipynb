{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RC-Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX3Skpqyc9i4"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf \r\n",
        "from tensorflow.keras.layers import LSTM, GRU, Activation, Conv1D, BatchNormalization,Dense,Bidirectional\r\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--fLLIWwc-a-"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, N, d_model):\r\n",
        "        super(PositionalEncoding, self).__init__()\r\n",
        "        self.pos_encoding = self.positional_encoding(N, d_model)\r\n",
        "\r\n",
        "    def get_angles(self, position, i, d_model):\r\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\r\n",
        "        return position * angles\r\n",
        "\r\n",
        "    def positional_encoding(self, N, d_model):\r\n",
        "        angle_rads = self.get_angles(\r\n",
        "            position=tf.range(N, dtype=tf.float32)[:, tf.newaxis],\r\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\r\n",
        "            d_model=d_model)\r\n",
        "\r\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\r\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\r\n",
        "\r\n",
        "        angle_rads = np.zeros(angle_rads.shape)\r\n",
        "        angle_rads[:, 0::2] = sines\r\n",
        "        angle_rads[:, 1::2] = cosines\r\n",
        "        pos_encoding = tf.constant(angle_rads)\r\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\r\n",
        "\r\n",
        "        print(pos_encoding.shape)\r\n",
        "        return tf.cast(pos_encoding, tf.float32)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFs3yut9c-hY"
      },
      "source": [
        "def create_padding_mask(multiple_qk):\r\n",
        "    mask = tf.cast(tf.math.equal(multiple_qk,0), tf.float32)\r\n",
        "    return mask * -1e9"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXd91iDOc-lK"
      },
      "source": [
        "def create_look_ahead_mask(attention_score_matrix):\r\n",
        "    N = tf.shape(attention_score_matrix)[2]\r\n",
        "\r\n",
        "    mask = tf.ones(shape=(N, N), dtype=tf.float32)\r\n",
        "    #mask = tf.experimental.numpy.triu(mask, 1) \r\n",
        "    \r\n",
        "    mask = 1 - tf.linalg.band_part(mask, -1, 0)\r\n",
        "    mask = mask[tf.newaxis, :, :] * -1e9\r\n",
        "\r\n",
        "    pad_mask = create_padding_mask(attention_score_matrix)\r\n",
        "    return tf.minimum(mask, pad_mask)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzMPHZUc-nV"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask_type):\r\n",
        "\r\n",
        "    # Attention Score : Q * K^T\r\n",
        "    attention_score_matrix = tf.matmul(query, key, transpose_b=True)\r\n",
        "    \r\n",
        "    # Scaling : Divide by sqrt(d_k)\r\n",
        "    d_k = tf.cast(key.shape[-1], tf.float32)\r\n",
        "    scaled_matrix = attention_score_matrix / tf.math.sqrt(d_k)\r\n",
        "\r\n",
        "    # Padding Mask or Look-Ahead Mask\r\n",
        "    if mask_type is 'padding':\r\n",
        "        scaled_matrix += create_padding_mask(scaled_matrix)\r\n",
        "    elif mask_type is 'look_ahead':\r\n",
        "        scaled_matrix += create_look_ahead_mask(scaled_matrix)\r\n",
        "\r\n",
        "    # Softmax fuction\r\n",
        "    attention_weights = tf.nn.softmax(scaled_matrix, axis=-1) \r\n",
        "\r\n",
        "    # Weighted Sum : multiply V matrix\r\n",
        "    attention_value = tf.matmul(attention_weights, value)\r\n",
        "\r\n",
        "    return attention_value, attention_weights"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Nilxr1c-qq"
      },
      "source": [
        "def printShape(Q, K, V, status):\r\n",
        "    print(\"[{status}] Q shape : {q}, K shape : {k}, V shape : {v}\\n\".format(status=status, q=Q.shape, k=K.shape, v=V.shape))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KLZ63Fnc-s0"
      },
      "source": [
        "class MultiHeadAttention:\r\n",
        "    def __init__(self, num_heads, d_model):\r\n",
        "        self.num_heads = num_heads\r\n",
        "        self.d_model = d_model\r\n",
        "        \r\n",
        "        assert d_model % num_heads == 0, \"depth가 정수 형식이 아닙니다.\"\r\n",
        "        self.depth = self.d_model // self.num_heads\r\n",
        "\r\n",
        "        # Dense 층의 출력 차원은 d_model\r\n",
        "        self.WQ = tf.keras.layers.Dense(units=self.d_model)\r\n",
        "        self.WK = tf.keras.layers.Dense(units=self.d_model)\r\n",
        "        self.WV = tf.keras.layers.Dense(units=self.d_model)\r\n",
        "        self.WO = tf.keras.layers.Dense(units=self.d_model)\r\n",
        "\r\n",
        "    \r\n",
        "    def get_attention(self, query, key, value, mask_type=None):\r\n",
        "\r\n",
        "        printShape(query, key, value, \"Input\")\r\n",
        "        \r\n",
        "        def split_sequences(batch_size, num_heads, d_model, query, key, value):\r\n",
        "            Q_list = tf.reshape(query, (batch_size, -1, num_heads, d_model // num_heads))\r\n",
        "            K_list = tf.reshape(key, (batch_size, -1, num_heads, d_model // num_heads))\r\n",
        "            V_list = tf.reshape(value, (batch_size, -1, num_heads, d_model // num_heads))\r\n",
        "\r\n",
        "            return tf.transpose(Q_list, perm=[0, 2, 1, 3]), tf.transpose(K_list, perm=[0, 2, 1, 3]), tf.transpose(V_list, perm=[0, 2, 1, 3])\r\n",
        "            \r\n",
        "        # 현재 batch_size는 1이다.\r\n",
        "        # 모델 훈련에서의 batch 당 token의 수를 의미한다.\r\n",
        "        batch_size = tf.shape(query)[0]\r\n",
        "\r\n",
        "        # Q*W^Q : Dense 층 구성\r\n",
        "        q_WQ = self.WQ(query)\r\n",
        "        k_WK = self.WK(key)\r\n",
        "        v_WV = self.WV(value)\r\n",
        "        printShape(q_WQ, k_WK, v_WV, \"Dense\")\r\n",
        "\r\n",
        "        # num_heads로 입력 행렬 분할\r\n",
        "        # (batch_size, 입력 시퀀스 개수, d_model) -> (batch_size, num_heads, 입력 시퀀스 개수, d_model/num_heads)\r\n",
        "        Q_list, K_list, V_list = split_sequences(batch_size, self.num_heads, self.d_model, q_WQ, k_WK, v_WV)\r\n",
        "        printShape(Q_list, K_list, V_list, \"Splited\")\r\n",
        "\r\n",
        "        # Attention value \r\n",
        "        scaled_attention, _ = scaled_dot_product_attention(Q_list, K_list, V_list, mask_type)\r\n",
        "        \r\n",
        "        # head를 연결하기 위한 Tensor shape 조정\r\n",
        "        # (batch_size, num_heads, 입력 시퀀스 개수, d_model/num_heads) -> (batch_size, 입력 시퀀스 개수, num_heads, d_model/num_heads)\r\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\r\n",
        "        \r\n",
        "        # head 연결\r\n",
        "        # (batch_size, 입력 시퀀스 개수, d_model)\r\n",
        "        concat_attention = tf.reshape(scaled_attention,(batch_size, -1, self.d_model))\r\n",
        "\r\n",
        "        # Multi-Head 최종 결과 값\r\n",
        "        result = self.WO(concat_attention)\r\n",
        "\r\n",
        "        return result\r\n",
        "        \r\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFOGMmBdEnv"
      },
      "source": [
        "class Encoder:\r\n",
        "    def __init__(self, N, layer_num, dff, d_model, num_heads, dropout):\r\n",
        "        self.N = N\r\n",
        "        self.layer_num = layer_num\r\n",
        "\r\n",
        "        self.dff = dff\r\n",
        "        self.d_model = d_model\r\n",
        "        self.num_heads = num_heads\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    def stack_encode_layer(self, layer_name):\r\n",
        "        \r\n",
        "        # Input 1개  : 인코더 입력\r\n",
        "        inputs = tf.keras.Input(shape=(None, self.d_model), name=\"encode_inputs\")\r\n",
        "\r\n",
        "        print(layer_name, \"sub-layer 1\")\r\n",
        "        # encoder의 self attention은 query, key, value가 모두 입력 문장의 단어 벡터를 의미한다.\r\n",
        "        # query = key = value\r\n",
        "        query = key = value = inputs\r\n",
        "        \r\n",
        "        # Multi-Head Attention\r\n",
        "        multi_head_attention = MultiHeadAttention(self.num_heads, self.d_model)\r\n",
        "        attention_value = multi_head_attention.get_attention(query, key, value, mask_type='padding')\r\n",
        "\r\n",
        "        attention_value = tf.keras.layers.Dropout(rate=self.dropout)(attention_value)\r\n",
        "        # Residual connection\r\n",
        "        attention_value += inputs\r\n",
        "        # Normalization\r\n",
        "        sublayer_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_value)\r\n",
        "\r\n",
        "        print(layer_name, \"sub-layer 2\")\r\n",
        "        # Feed Forward Network\r\n",
        "        # 입력과 출력의 크기가 보존되며, FFN의 은닉층 크기는 dff다.\r\n",
        "        feed_forward_net = tf.keras.layers.Dense(units=self.dff, activation='relu')(sublayer_output)\r\n",
        "        feed_forward_net = tf.keras.layers.Dense(units=self.d_model)(feed_forward_net)\r\n",
        "        \r\n",
        "        feed_forward_net = tf.keras.layers.Dropout(rate=self.dropout)(feed_forward_net)\r\n",
        "        # Residual connection\r\n",
        "        feed_forward_net += sublayer_output\r\n",
        "        # Normalization\r\n",
        "        encoder_layer_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(feed_forward_net)\r\n",
        "\r\n",
        "        return tf.keras.Model(inputs=[inputs], outputs=encoder_layer_output, name=layer_name)\r\n",
        "\r\n",
        "    def get_encoder(self):\r\n",
        "\r\n",
        "        encoder_input = tf.keras.Input(shape=(None, self.d_model), name=\"encoder_inputs\")\r\n",
        "\r\n",
        "        # Positional Encoding\r\n",
        "        inputs = PositionalEncoding(self.N, self.d_model)(encoder_input)\r\n",
        "        \r\n",
        "        # Encoder Layer 쌓기\r\n",
        "        # layer_num 만큼 encoder layer를 쌓는다\r\n",
        "        for idx in range(self.layer_num):\r\n",
        "            inputs = encoder_output = self.stack_encode_layer(layer_name=\"encoder_layer_{}\".format(idx))(inputs=[inputs])\r\n",
        "\r\n",
        "        return tf.keras.Model(inputs=[encoder_input], outputs=encoder_output, name=\"Encoder\")\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy-XHtkIdEr3"
      },
      "source": [
        "class RCEncoder:\r\n",
        "\r\n",
        "    def __init__(self, hidden_size, global_layers=1, cell='gru', dropout=0.1):\r\n",
        "        \r\n",
        "        self.hidden_size = hidden_size\r\n",
        "\r\n",
        "        self.sw1 = Sequential()\r\n",
        "        self.sw1.add(Conv1D(filters=hidden_size, kernel_size =1, padding='same'))\r\n",
        "        self.sw1.add(BatchNormalization())\r\n",
        "        self.sw1.add(Activation('relu'))\r\n",
        "\r\n",
        "        self.sw3 = Sequential()\r\n",
        "        self.sw3.add(Conv1D(filters=hidden_size, kernel_size =1, padding='same'))\r\n",
        "        self.sw3.add(Activation('relu'))\r\n",
        "        self.sw3.add(BatchNormalization())\r\n",
        "        self.sw3.add(Conv1D(filters=hidden_size, kernel_size =3, padding='same'))\r\n",
        "        self.sw3.add(Activation('relu'))\r\n",
        "        self.sw3.add(BatchNormalization())\r\n",
        "\r\n",
        "        self.sw33 = Sequential()\r\n",
        "        self.sw33.add(Conv1D(filters=hidden_size, kernel_size =1, padding='same'))\r\n",
        "        self.sw33.add(Activation('relu'))\r\n",
        "        self.sw33.add(BatchNormalization())\r\n",
        "        self.sw33.add(Conv1D(filters=hidden_size, kernel_size =3, padding='same'))\r\n",
        "        self.sw33.add(Activation('relu'))\r\n",
        "        self.sw33.add(BatchNormalization())\r\n",
        "        self.sw33.add(Conv1D(filters=hidden_size, kernel_size =3, padding='same'))\r\n",
        "        self.sw33.add(Activation('relu'))\r\n",
        "        self.sw33.add(BatchNormalization())\r\n",
        "\r\n",
        "        self.filter_linear = Sequential()\r\n",
        "        # self.filter_linear.add(Dense(3 * hidden_size))\r\n",
        "        self.filter_linear.add(Dense(hidden_size, activation='sigmoid'))\r\n",
        "\r\n",
        "        self.rnn = Sequential()\r\n",
        "        if cell == 'gru':\r\n",
        "            for layer_idx in range(global_layers):\r\n",
        "                self.rnn.add(Bidirectional(GRU(units=hidden_size, dropout=dropout, return_sequences=True)))\r\n",
        "                \r\n",
        "        else:\r\n",
        "            for layer_idx in range(global_layers):\r\n",
        "                self.rnn.add(Bidirectional(LSTM(units=hidden_size, dropout=dropout, return_sequences=True)))\r\n",
        "                \r\n",
        "        self.rnn.add(Dense(units=hidden_size))\r\n",
        "                             \r\n",
        "    def get_encoder(self, rc_encoder_input):\r\n",
        "        \r\n",
        "        #rc_encoder_input = tf.keras.Input(shape=(None, self.hidden_size), name=\"rc_encoder_inputs\")\r\n",
        "        outputs = self.rnn(rc_encoder_input) # (Batch_size, Length, Hidden_size)\r\n",
        "        #outputs = tf.concat((outputs[-1, :, :self.hidden_size], outputs[0, :, self.hidden_size:]), 0)\r\n",
        "        \r\n",
        "        conv1 = self.sw1(outputs) \r\n",
        "        conv3 = self.sw3(outputs)\r\n",
        "        conv33 = self.sw33(outputs)\r\n",
        "                             \r\n",
        "        conv = tf.concat((conv1, conv3, conv33), -1) # (Batch_size, Length, 3 * Hidden_size)\r\n",
        "        conv = self.filter_linear(conv) # (Batch_size, Length, Hidden_size)\r\n",
        "        # gate = self.sigmoid(conv)\r\n",
        "                             \r\n",
        "        outputs = outputs * conv\r\n",
        "        return outputs   \r\n",
        "        #return tf.keras.Model(inputs=[rc_encoder_input], outputs=outputs, name=\"Encoder\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkW9kB4ddEuc"
      },
      "source": [
        "class Decoder:\r\n",
        "    def __init__(self, N, layer_num, dff, d_model, num_heads, dropout):\r\n",
        "        self.N = N\r\n",
        "        self.layer_num = layer_num\r\n",
        "\r\n",
        "        self.dff = dff\r\n",
        "        self.d_model = d_model\r\n",
        "        self.num_heads = num_heads\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    def stack_decode_layer(self, layer_name):\r\n",
        "        print(layer_name, \"sub-layer 1\")\r\n",
        "        \r\n",
        "        #Input 2개 : 디코더 입력, 인코더 출력\r\n",
        "        decoder_input = tf.keras.Input(shape=(None, self.d_model), name=\"decoder_layer_input\")\r\n",
        "        encoder_output = tf.keras.Input(shape=(None, self.d_model), name=\"encoder_output\")\r\n",
        "        rc_encoder_output = tf.keras.Input(shape=(None, self.d_model), name=\"rc_encoder_output\")\r\n",
        "        \r\n",
        "        # Masked Multi-Head Self Attention\r\n",
        "        # 디코더의 Self Attention에서 query, key, value의 출처는 디코더 입력이다.\r\n",
        "        query = key = value = decoder_input\r\n",
        "\r\n",
        "        self_attention = MultiHeadAttention(self.num_heads, self.d_model)\r\n",
        "        attention_value = self_attention.get_attention(query, key, value, mask_type='look_ahead')\r\n",
        "\r\n",
        "        attention_value = tf.keras.layers.Dropout(rate=self.dropout)(attention_value)\r\n",
        "        # Residual connection\r\n",
        "        attention_value += decoder_input\r\n",
        "        # Normalization\r\n",
        "        sublayer_output_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_value)\r\n",
        "\r\n",
        "        # Multi-Head Encoder-Decoder Attention\r\n",
        "        # 디코더 Encoder-Decoder Attention의 입력 중 Q는 디코더 sub-layer의 출력이고, K,V는 인코더의 출력이다.\r\n",
        "        key_from_encoder = value_from_encoder = encoder_output\r\n",
        "        query_from_decoder = sublayer_output_1\r\n",
        "\r\n",
        "        key_from_rc_encoder = value_from_rc_encoder = rc_encoder_output\r\n",
        "        \r\n",
        "        print(layer_name, \"sub-layer 2\")\r\n",
        "        encoder_decoder_attention = MultiHeadAttention(self.num_heads, self.d_model)\r\n",
        "        attention_output = encoder_decoder_attention.get_attention(query_from_decoder, key_from_encoder, value_from_encoder, mask_type='padding')\r\n",
        "\r\n",
        "        attention_output = tf.keras.layers.Dropout(rate=self.dropout)(attention_output)\r\n",
        "        attention_output += sublayer_output_1\r\n",
        "        encoder_attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_output)\r\n",
        "        \r\n",
        "        rc_encoder_decoder_attention = MultiHeadAttention(self.num_heads, self.d_model)\r\n",
        "        rc_attention_output = rc_encoder_decoder_attention.get_attention(query_from_decoder, key_from_rc_encoder, value_from_rc_encoder, mask_type='padding')\r\n",
        "\r\n",
        "        rc_attention_output = tf.keras.layers.Dropout(rate=self.dropout)(rc_attention_output)\r\n",
        "        rc_attention_output += sublayer_output_1\r\n",
        "        rc_encoder_attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(rc_attention_output)\r\n",
        "\r\n",
        "        concat_attention = tf.concat([encoder_attention, rc_encoder_attention], -1)\r\n",
        "        gated = tf.keras.layers.Dense(self.d_model, activation='sigmoid')(concat_attention)\r\n",
        "        sublayer_output_2 = tf.linalg.matmul(gated, encoder_attention) + tf.linalg.matmul((1 - gated), rc_encoder_attention)\r\n",
        "                \r\n",
        "        print(layer_name, \"sub-layer 3\")\r\n",
        "        # Feed Forward Network\r\n",
        "        # 입력과 출력의 크기가 보존되며, FFN의 은닉층 크기는 dff다.\r\n",
        "        feed_forward_net = tf.keras.layers.Dense(units=self.dff, activation='relu')(sublayer_output_2)\r\n",
        "        feed_forward_net = tf.keras.layers.Dense(units=self.d_model)(feed_forward_net)\r\n",
        "\r\n",
        "        feed_forward_net = tf.keras.layers.Dropout(rate=self.dropout)(feed_forward_net)\r\n",
        "        # Residual connection\r\n",
        "        feed_forward_net += sublayer_output_2\r\n",
        "        # Normalization\r\n",
        "        decoder_layer_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(feed_forward_net)\r\n",
        "\r\n",
        "        return tf.keras.Model(inputs=[decoder_input, encoder_output, rc_encoder_output], outputs=decoder_layer_output, name=layer_name)\r\n",
        "\r\n",
        "\r\n",
        "    def get_decoder(self):\r\n",
        "        \r\n",
        "        #Input 4개 : 디코더 입력, 인코더 출력, Look-ahead mask, padding mask\r\n",
        "        decoder_input = tf.keras.Input(shape=(None, self.d_model), name=\"decoder_inputs\")\r\n",
        "        encoder_output = tf.keras.Input(shape=(None, self.d_model), name=\"encoder_outputs\")\r\n",
        "        rc_encoder_output = tf.keras.Input(shape=(None, self.d_model), name=\"rc_encoder_outputs\")\r\n",
        "\r\n",
        "        # Positional Encoding\r\n",
        "        inputs = PositionalEncoding(self.N, self.d_model)(decoder_input)\r\n",
        "        \r\n",
        "        # Decoder Layer 쌓기\r\n",
        "        # layer_num 만큼 decoder layer를 쌓는다\r\n",
        "        for idx in range(self.layer_num):\r\n",
        "            inputs = decoder_output = self.stack_decode_layer(layer_name=\"decoder_layer_{}\".format(idx))(inputs=[inputs, encoder_output, rc_encoder_output])\r\n",
        "\r\n",
        "        return tf.keras.Model(inputs=[decoder_input, encoder_output, rc_encoder_output], outputs=decoder_output, name=\"Decoder\")\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXSaa7mndH4R"
      },
      "source": [
        "class Transformer:\r\n",
        "    def __init__(self, vocab_size, layer_num, dff, d_model, num_heads, dropout=0.1):\r\n",
        "        \r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.layer_num = layer_num\r\n",
        "\r\n",
        "        self.dff = dff\r\n",
        "        self.d_model = d_model\r\n",
        "        self.num_heads = num_heads\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    '''\r\n",
        "    encoder input : 인코더의 입력은, 요약하지 않은 문장을 토큰화하여 임베딩한 벡터들.\r\n",
        "    decoder input : 디코더의 입력은 요약된 문장을 토큰화하여 임베딩한 벡터들.\r\n",
        "    '''\r\n",
        "    def get_transformer(self):\r\n",
        "        \r\n",
        "        #Input 2개 : 인코더 입력, 디코더 입력\r\n",
        "        encoder_input = tf.keras.Input(shape=(None, self.d_model), name=\"encoder_inputs\")\r\n",
        "        decoder_input = tf.keras.Input(shape=(None, self.d_model), name=\"decoder_inputs\")\r\n",
        "\r\n",
        "        #인코더\r\n",
        "        encoder = Encoder(self.vocab_size, self.layer_num, self.dff, self.d_model, self.num_heads, self.dropout)\r\n",
        "        encoder_output = encoder.get_encoder()(inputs=[encoder_input])\r\n",
        "        \r\n",
        "        # RC 인코더\r\n",
        "        rc_encoder = RCEncoder(hidden_size=self.d_model, global_layers=1, cell='gru', dropout=self.dropout)\r\n",
        "        #rc_encoder_output = rc_encoder.get_encoder()(inputs=[encoder_input])\r\n",
        "        rc_encoder_output = rc_encoder.get_encoder(encoder_input)\r\n",
        "        \r\n",
        "        #디코더\r\n",
        "        decoder = Decoder(self.vocab_size, self.layer_num, self.dff, self.d_model, self.num_heads, self.dropout)\r\n",
        "        decoder_output = decoder.get_decoder()(inputs=[decoder_input, encoder_output, rc_encoder_output])\r\n",
        "\r\n",
        "        '''\r\n",
        "        디코더에서는 인코더의 행렬과 디코더의 입력을 통해 다음 단어를 예측한다.\r\n",
        "        디코더의 출력은 임베딩 벡터의 개수 summary vocab size의 크기를 가지며, 확률 값을 가진다.\r\n",
        "        '''\r\n",
        "        # 단어 예측을 위한 출력층\r\n",
        "        output = tf.keras.layers.Dense(units=self.vocab_size, activation='softmax', name=\"Output\")(decoder_output)\r\n",
        "\r\n",
        "        return tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=output, name=\"Transformer\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leYgZnK-dJyb"
      },
      "source": [
        "class LearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "    def __init__(self, d_model, warmup_steps=4000):\r\n",
        "        super(LearningRate, self).__init__()\r\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\r\n",
        "        self.warmup_steps = warmup_steps\r\n",
        "    \r\n",
        "    def __call__(self, step_num):\r\n",
        "        min_val = tf.math.minimum(tf.math.rsqrt(step_num),\r\n",
        "                                  step_num * (self.warmup_steps ** -1.5))\r\n",
        "        lrate = (self.d_model ** -0.5) * min_val\r\n",
        "        return lrate"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX3QvCOgdKwA"
      },
      "source": [
        "D_MODEL = 256\r\n",
        "LAYER_NUM = 6\r\n",
        "NUM_HEADS = 8\r\n",
        "DFF = 512\r\n",
        "VOCAB_SIZE = 5000\r\n",
        "\r\n",
        "BATCH_SIZE = 64\r\n",
        "BUFFER_SIZE = 20000\r\n",
        "\r\n",
        "WARMUP_STEPS = 50\r\n",
        "EPOCHS = 70"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHOKYimZdLxm",
        "outputId": "10e2ce44-0aba-41d6-b020-589fca186743"
      },
      "source": [
        "model = Transformer(\r\n",
        "    vocab_size=VOCAB_SIZE,\r\n",
        "    layer_num=LAYER_NUM,\r\n",
        "    dff=DFF,\r\n",
        "    d_model=D_MODEL,\r\n",
        "    num_heads=NUM_HEADS,\r\n",
        "    dropout = 0.3).get_transformer()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5000, 256)\n",
            "encoder_layer_0 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_0 sub-layer 2\n",
            "encoder_layer_1 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_1 sub-layer 2\n",
            "encoder_layer_2 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_2 sub-layer 2\n",
            "encoder_layer_3 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_3 sub-layer 2\n",
            "encoder_layer_4 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_4 sub-layer 2\n",
            "encoder_layer_5 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "encoder_layer_5 sub-layer 2\n",
            "(1, 5000, 256)\n",
            "decoder_layer_0 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_0 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_0 sub-layer 3\n",
            "decoder_layer_1 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_1 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_1 sub-layer 3\n",
            "decoder_layer_2 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_2 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_2 sub-layer 3\n",
            "decoder_layer_3 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_3 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_3 sub-layer 3\n",
            "decoder_layer_4 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_4 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_4 sub-layer 3\n",
            "decoder_layer_5 sub-layer 1\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_5 sub-layer 2\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "[Input] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Dense] Q shape : (None, None, 256), K shape : (None, None, 256), V shape : (None, None, 256)\n",
            "\n",
            "[Splited] Q shape : (None, 8, None, 32), K shape : (None, 8, None, 32), V shape : (None, 8, None, 32)\n",
            "\n",
            "decoder_layer_5 sub-layer 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf6WQyZvdL1B",
        "outputId": "f9e33faf-13dd-46a2-b814-64d44f4f51e8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None, 256)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, None, 256)    920832      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 256)    66816       sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 256)    264704      sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, None, 256)    462592      sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, None, 768)    0           sequential[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, None, 256)    196864      tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None, 256)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder (Functional)            (None, None, 256)    3162624     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_6 (TFOpLambda) (None, None, 256)    0           sequential_4[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Decoder (Functional)            (None, None, 256)    7114752     decoder_inputs[0][0]             \n",
            "                                                                 Encoder[0][0]                    \n",
            "                                                                 tf.math.multiply_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Output (Dense)                  (None, None, 5000)   1285000     Decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 13,474,184\n",
            "Trainable params: 13,471,112\n",
            "Non-trainable params: 3,072\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahcJWn8LdKy5"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}