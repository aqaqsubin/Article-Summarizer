{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Setting -> GPU 1번 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델의 구성 -> Transformer_Implement.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Transformer_Implement as ti\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/data/ksb/TestDir\"\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, 'sample_articles')\n",
    "\n",
    "PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Preprocessed-Data\")\n",
    "MINI_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Preprocessed-Data\")\n",
    "\n",
    "SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Summary-Preprocessed-Data\")\n",
    "MINI_SUMMARY_PREPROCESSED_PATH = os.path.join(DATA_BASE_DIR,\"Mini-Summary-Preprocessed-Data\")\n",
    "\n",
    "MODEL_BASE_DIR = os.path.join(os.path.join(BASE_DIR, 'articleSummary-Jupyter'), 'Word-Embedding')\n",
    "glove_model_path = os.path.join(MODEL_BASE_DIR, 'glove-256.model')\n",
    "corpus_model_path = os.path.join(MODEL_BASE_DIR, 'corpus-256.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    import errno\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def del_folder(path):\n",
    "    from shutil import rmtree\n",
    "    try:\n",
    "        rmtree(path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_switched_root_dir(path, save_root_dir):\n",
    "    path_token = path.split(os.sep)\n",
    "    path_token[4] = save_root_dir.split(os.sep)[4]\n",
    "    save_dir_path = os.sep.join(path_token[:6])\n",
    "    \n",
    "    return save_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCopier:\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = f.readlines()\n",
    "\n",
    "    def copy_article(self, save_dir):\n",
    "        mkdir_p(save_dir)\n",
    "        article_name = str(len(os.listdir(save_dir)))+\".txt\"\n",
    "\n",
    "        with open(os.path.join(save_dir, article_name), 'w', encoding='utf-8') as new_f:\n",
    "            new_f.writelines(self.lines)\n",
    "\n",
    "def load_proc_data(summary_path):\n",
    "\n",
    "    media_list = sorted(os.listdir(summary_path))\n",
    "        \n",
    "    for media_name in media_list:\n",
    "    \n",
    "        media_path = os.path.join(summary_path, media_name)\n",
    "        article_list = os.listdir(media_path)\n",
    "            \n",
    "        article_path_list = [os.path.join(media_path, article_name) for article_name in article_list]\n",
    "        \n",
    "        origin_root = PREPROCESSED_PATH\n",
    "        new_root = MINI_PREPROCESSED_PATH\n",
    "        \n",
    "        origin_proc_path_list = [os.path.join(get_switched_root_dir(path, origin_root), path.split(os.sep)[-1]) for path in article_path_list]\n",
    "        new_proc_path_list = [get_switched_root_dir(path, new_root) for path in article_path_list]\n",
    "\n",
    "        for origin_path, new_path in zip(origin_proc_path_list, new_proc_path_list):\n",
    "            article = ArticleCopier(origin_path)\n",
    "            article.copy_article(new_path)\n",
    "        map(lambda article : article.copy_article, new_proc_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del_folder(MINI_PREPROCESSED_PATH)\n",
    "#MINI_PREPROCESSED_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_proc_data(MINI_SUMMARY_PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치와 함께 임베딩 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/ksb/TestDir/articleSummary-Jupyter/Word-Embedding/glove-256.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6f2dd0ad98ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/glove/glove.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msavefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/ksb/TestDir/articleSummary-Jupyter/Word-Embedding/glove-256.model'"
     ]
    }
   ],
   "source": [
    "glove = Glove.load(glove_model_path)\n",
    "corpus = Corpus.load(corpus_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawTextReader:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.rgxSplitter = re.compile(\"/n\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filepath, encoding='utf-8'):\n",
    "            ch = self.rgxSplitter.split(line)\n",
    "            for s in ch:\n",
    "                yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegerEncoder:\n",
    "    def __init__(self, filepath, corpus):\n",
    "        self.filepath = filepath\n",
    "        self.corpus = corpus\n",
    "    \n",
    "    def get_encoded_vec_matrix(self):\n",
    "        media_list = os.listdir(self.filepath)\n",
    "        \n",
    "        encoded_vec_list = []\n",
    "        for media_name in media_list:\n",
    "    \n",
    "            media_path = os.path.join(self.filepath, media_name)\n",
    "            article_list = os.listdir(media_path)\n",
    "            \n",
    "            for article_name in article_list:\n",
    "                \n",
    "                reader = RawTextReader(os.path.join(media_path, article_name)) \n",
    "                content = list(filter(None, reader))\n",
    "                vec = np.array([corpus.dictionary[token] for sent in content for token in sent.split() if token in corpus.dictionary])\n",
    "                \n",
    "                encoded_vec_list.append(vec)\n",
    "\n",
    "        return np.array(encoded_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "LAYER_NUM = 6\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "VOCAB_SIZE = len(corpus.dictionary)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "WARMUP_STEPS = 50\n",
    "EPOCHS = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [VOCAB_SIZE], [VOCAB_SIZE + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> Token : [65850]\n",
      "<EOS> Token : [65851]\n",
      "Vocabulary Size : 65852\n"
     ]
    }
   ],
   "source": [
    "print('<SOS> Token : {}'.format(START_TOKEN))\n",
    "print('<EOS> Token : {}'.format(END_TOKEN))\n",
    "\n",
    "VOCAB_SIZE += 2\n",
    "print('Vocabulary Size : {}'.format(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 된 59,604개의 기사 본문 데이터에 정수 인코딩을 수행한다.  \n",
    "\n",
    "정수 인코딩 수행 후에 (59604, None)의 크기를 가지는 Matrix가 되며,   \n",
    "각 인코딩된 값을 임베딩 벡터 값으로 대체한 후에는 (59604, `max_token`, 256)의 크기를 가지는 Tensor가 된다.  \n",
    "- `max_token`은 각 기사 본문의 토큰 수 중 가장 큰 값을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 기사의 토큰에 대해 정수 인코딩을 수행한 결과 행렬을 `train_encoded_matrix`, `target_encoded_matrix`로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-730a378d8bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntegerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMINI_PREPROCESSED_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_encoded_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoded_vec_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_encoded_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e687414b6fcb>\u001b[0m in \u001b[0;36mget_encoded_vec_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRawTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedia_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b411eea54922>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgxSplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \"\"\"\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_encoder = IntegerEncoder(MINI_PREPROCESSED_PATH, corpus)\n",
    "train_encoded_matrix = train_encoder.get_encoded_vec_matrix()\n",
    "train_encoded_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_length = lambda x : np.max([len(x[idx]) for idx in range(len(x))])\n",
    "MAX_LEN = get_max_length(train_encoded_matrix)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = IntegerEncoder(MINI_SUMMARY_PREPROCESSED_PATH, corpus)\n",
    "target_encoded_matrix = target_encoder.get_encoded_vec_matrix()\n",
    "target_encoded_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_max_len = get_max_length(target_encoded_matrix)\n",
    "MAX_LEN = target_max_len if target_max_len > MAX_LEN else MAX_LEN\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기사의 시작과 끝을 알리는 <*SOS*>,<*EOS*>을 붙이고,  \n",
    "nd-array로 저장하기 위해 패딩을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_padding(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (content, summary) in zip(inputs, outputs):\n",
    "        # Add Start Token, End Token\n",
    "        content = START_TOKEN + content + END_TOKEN\n",
    "        summary = START_TOKEN + summary + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(content)\n",
    "        tokenized_outputs.append(summary)\n",
    "\n",
    "    # Padding\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LEN, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LEN, padding='post')\n",
    "        \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents, summaries = encode_and_padding(train_encoded_matrix, target_encoded_matrix)\n",
    "\n",
    "print('Contents Shape : {}'.format(contents.shape))\n",
    "print('Summaries Shape : {}'.format(summaries.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수 인코딩을 수행한 결과행렬에 정수를 임베딩 벡터로 변환한다.  \n",
    "이의 결과로 (59604, 4392, 256)의 dimension을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOS, EOS 토큰에 대한 임베딩 벡터 값도 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_vector(int_enc_vec):\n",
    "    return np.array([glove.word_vectors[integer] for integer in int_enc_vec])\n",
    "\n",
    "def embedding_matrix(int_enc_matrix):\n",
    "    row_list = []\n",
    "    for idx, row_vec in enumerate(int_enc_matrix):\n",
    "        emb_Vec = embedding_vector(row_vec)\n",
    "        row_list.append(emb_Vec)\n",
    "    return np.array(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_matrix = embedding_matrix(train_encoded_matrix)\n",
    "target_embedded_matrix = embedding_matrix(target_encoded_matrix)\n",
    "\n",
    "print('Train Embedded Matrix Shape : {}'.format(train_embedded_matrix.shape))\n",
    "print('Target Embedded Matrix Shape : {}'.format(target_embedded_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'encoder_inputs': contents, # Encoder Input\n",
    "        'decoder_inputs': summaries[:, :-1] # Decoder Input\n",
    "    },\n",
    "    {\n",
    "        # Decoder Output, Remove <SOS>\n",
    "        'Output': summaries[:, 1:]  \n",
    "    },\n",
    "))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률 Learning Rate 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate_scheduler = ti.LearningRate(d_model=D_MODEL, warmup_steps=WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9  \n",
    "beta_2 = 0.98\n",
    "epsilon = 10 ** -9\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lrate_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ti.Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    layer_num=LAYER_NUM,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS).get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./Transformer-Train-GloVe.ipynb ./Transformer-Train-Word2Vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
    "\n",
    "model.fit(x=train_embedded_matrix, y=target_embedded_matrix, batch_size=16, epochs=EPOCHS, shuffle=True, callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
