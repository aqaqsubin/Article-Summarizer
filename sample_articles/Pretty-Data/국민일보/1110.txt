미국에서 한 흑인이 경찰에 체포되는 과정에서 사망한 사건을 계기로 인종 차별에 항의하는 시위가 거세게 일고 있다./n 이제는 미국을 넘어 세계 곳곳에서 유사한 항의가 나타나고 있다./n 인종 차별이 주된 항의의 대상이지만 그 이외에도 온갖 사회적 차별에 대한 항의의 목소리가 높아지고 있다./n최근 몇몇 글로벌 정보기술 기업들이 안면인식 기술의 이용에 제한을 두겠다는 발표를 했다./n IBM은 안면인식 기술 개발을 아예 중단하겠다고 발표했고, 아마존에서는 자신의 안면인식 기술을 향후 1년간 경찰에 제공하지 않겠다고 밝혔다./n 뒤이어 마이크로소프트에서도 안면인식 기술을 어떻게 규율할 것인지에 대한 법이 마련될 때까지 경찰에 기술 제공을 하지 않을 것이라고 발표했다./n 차별에 관한 사회적 논란의 와중에 안면인식 기술이 왜 특히 주목을 받는가?/n안면인식 기술을 포함한 이미지 인식기술은 인공지능이 뛰어난 성과를 보이는 주요 영역으로 인정받고 있다./n 서로 다른 이미지 유형에 대해 분류를 해서 판단하는 것은 지도학습 인공지능의 중요한 영역이다./n 안면인식 기술은 개인에 관한 인증이나 식별을 위한 목적으로 응용돼 활용되기도 한다./n이런 방식의 인공지능이 전제하는 중요한 ‘재료’는 데이터다./n 안면인식 기술의 발전을 위해서는 사회 구성원들의 얼굴 특징을 충분히 반영한 학습용 사진 데이터의 존재가 핵심 전제이다./n 만일 학습용 데이터 자체가 부족하거나 사회 구성원의 통계적 특징을 고르게 반영하지 못한다면 이로부터 훈련된 인공지능은 올바른 판단을 하지 못할 가능성이 높다./n 그 경우 안면인식 기술의 전반적인 정확도에 문제가 있을 수도 있고, 일부 사회 구성원에 대해서는 특히 오류가 많은 판단을 내릴 수도 있다./n 이미 안면인식 기술이 소수인종이나 여성에 대해 부정확한 판단을 내리는 경우가 많다는 연구결과가 몇 차례 나왔다./n 몇몇 기업들이 안면인식 기술의 활용에 제한을 두겠다고 발표한 것은 이러한 맥락을 배경으로 한 것이다./n그런데 안면인식 기술이 인구 구성별로 고른 판단을 하지 못한다고 해서 기술 자체를 탓할 수는 없다./n 오류나 편향이 발생하는 핵심적 원인은 학습용 데이터에 있기 때문이다./n 학습용 데이터에 흔히 백인 남성의 데이터가 많이 포함되는 반면 소수인종이나 여성의 데이터는 상대적으로 적게 포함되는 경우가 많아 인공지능에 한계가 나타나는 것이다./n 실제로 작년에 미국에서 상용화된 안면인식 기술을 대상으로 진행된 한 연구에서는 안면인식 기술이 전반적으로 소수인종에 대한 정확도가 떨어지는 것을 확인하는 한편, 아시아에서 개발된 안면인식 기술은 동양인에 대한 인식의 정확도가 상대적으로 높다는 결론을 내린 바 있다./n 아시아에서 개발된 인공지능은 학습 과정에서 동양인 이미지를 많이 이용했기 때문에 동양인에 대해 더 정확한 판단이 가능하게 된 것으로 짐작할 수 있다./n이런 연구에 비춰 우리나라에서도 안면인식 기술의 개발을 본격화해야 한다는 주장이 나올 수도 있다./n 하지만 그에 앞서 생각해야 하는 것은 어떻게 편향이 없는 학습용 데이터를 구축할 것인가의 문제다./n 학습용 데이터를 구축함에 있어 가장 기본적인 출발점은 데이터가 모집단의 통계적 특성을 풍부하고 정확하게 반영해야 한다는 것이다./n 데이터 경제의 활성화를 위해 학습용 데이터를 구축하는 경우에도 데이터 구축 과정에서 어떻게 편향을 최소화할 수 있을 것인지 함께 고민하는 것이 필수적이다./n 그렇지 않으면 뒤늦게 해당 기술의 활용을 멈춰야 하는 상황이 나타날 수도 있다.