 라디오 □ 방송일시 :/n 2020년 4월 21일 □ 출연자 :/n 이청호 한국인공지능윤리협회 회장- '딥페이크 포르노' 6월 25일부터 처벌받는다- 디지털 노출이 전제된 '딥페이크 포르노' 혼자 봐도 윤리적 문제- 잡아낼 기술 있지만./n./n./n더 정교해지는 딥페이크 기술- '국회 법사위, N번방 사건 혼동' 인공지능 지식 부족하고 딥페이크는 단순히 혼자 보는 것 아냐- '나쁜 딥페이크 추방 캠페인' 서명운동으로 진행 중* 아래 텍스트는 실제 방송 내용과 차이가 있을 수 있으니 보다 정확한 내용은 방송으로 확인하시기 바랍니다./n◇ 노영희 변호사:/n 오늘은 과학의 날입니다./n 과학기술의 발전은 이로운 것이지만, 그 반대편엔 어두운 면도 존재합니다./n AI의 발전으로 우리의 생활은 편리해졌지만, 인공지능을 이용해 다른 사람의 얼굴을 합성하고 진짜인 것처럼 구현해내는 딥페이크 영상도 성행했는데요./n 최근엔 N번방을 수사하던 경찰이 이 딥페이크 음란물 유포자를 잡아냈는데 이들은 IT 기술자들이었습니다./n 나쁜 딥페이크를 추방하기 위한 캠페인을 벌여왔던 한국인공지능윤리협회 이청호 회장 이 자리에 나와 주셨는데요./n 딥페이크에 관한 이야기 나눠보겠습니다./n 회장님 안녕하세요?/n◆ 이청호 한국인공지능윤리협회 회장:/n 네, 안녕하세요./n◇ 노영희:/n 먼저 '딥페이크'라는 게 정확히 뭡니까?/n◆ 이청호:/n 딥페이크 기술이라고 하는 것은 2014년에 이안 굿펠로우라고 하는 학자가 국제학술대회에서 발표를 했는데요./n 겐이라고 하는 인공지능 알고리즘을 발표했습니다./n 이 겐이라고 하는 인공지능 알고리즘은 생성적, 적대적, 그런 신경망 알고리즘이라고 할 수 있겠는데요./n 이것은 뭐냐면 두 개의 역할을 맡고 있는 인공지능이 있는 겁니다./n 그래서 한 인공지능은 뭔가를 계속 만들어내는 거죠./n 생성하는 거죠./n 그리고 다른 인공지능을 그것을 평가하는, 적대적인 입장에서 그것이 뭐가 잘못되었는지를 평가하는 그런 알고리즘이죠./n 그래서 일단 생성적 알고리즘이 이미지 같은 것을 만들어내면 적대적인 그러한 알고리즘이 그것을 감별을 해서 어떤 점이 잘못됐고, 어떤 점이 부족한 지를 지적을 하는 거죠./n 계속 그런 감별기술이 발전하다 보면 만들어내는 기술도 더 발전을 하게 되는 이런 원리를 이용한 것이 바로 딥페이크에 사용된 인공지능 알고리즘입니다./n◇ 노영희:/n 그러니까 딥페이크라고 하는 것은 특정 인물의 얼굴을 인공지능 기술을 이용해서 영상에 합성한 편집물을 말하는 거고, 그 딥페이크 기술이라고 하는 것은 그러한 딥페이크에 대해서 적대적, 생성적, 양측이 반대적인 측면에서 작동하는 그러한 인공지능 기술을 말하는 건가요?/n◆ 이청호:/n 네, 그렇습니다./n 딥페이크 영상을 만드는 기술에 그런 겐이라고 하는 인공지능 알고리즘이 적용된 거죠./n◇ 노영희:/n 적용돼서 뭘 어떻게 한다는 겁니까?/n◆ 이청호:/n 이미지를 만들어내면 그것을 평가하는 그런 알고리즘이 동시에 작동을 해서 계속 결과물이 좋은 방향으로, 그러니까 합성된 것인지, 아닌지를 알 수 없는 그런 방향으로, 사람들이 합성된 것인지를 모르는 방향으로 발전을 한다는 거죠./n 더 정교하고 고도화된 이미지를 제작할 수 있게 된다는 거죠./n◇ 노영희:/n 일단 알 것 같기도 하고, 모를 것 같기도 하고./n 중요한 것은 딥페이크라고 하는 것이 특정 인물의 얼굴 등을 합성해서 다른 사람에게 거짓, 가짜로 인식하게 만드는 그런 것을 의미하는 거다./n 여기까지만 정리를 하고 이야기를 이어보겠습니다./n 네덜란드의 딥페이크 연구 보고서에 따르면, 딥페이크로 만들어진 영상의 96%가 포르노로 소비되고 있다고 하고요./n 이중에 25%가 바로 한국 여성 연예인의 얼굴이더라, 이런 이야기거든요?/n 이것은 왜 그러는 겁니까?/n◆ 이청호:/n 그 기업에서 연구한 것으로 알고 있는데요./n 아무래도 케이팝 등의 영향으로 인해서 한국 연예인들의 인기가 높아졌기 때문에 한국 연예인들을 대상으로 한 그런 영상물이 제작된 거라고 저는 파악하고 있습니다./n◇ 노영희:/n 케이팝이 인기를 얻으면서 한국 연예인들의 얼굴을 합성해서 소비하는 상태로, 특히 포르노 쪽에서 많이 사용되고 있다고 하는 이야기시고요./n 그런데요./n 연예인이나 정치인 등 유명인뿐만 아니라 요즘에는 일반인들도 딥페이크의 피해자가 되고 있지 않습니까?/n 그래서 이것이 놀라웠는데, N번방을 수사한 경찰이 확인을 해봤더니 이런 식의 딥페이크 음란물, 가짜 얼굴이 합성된 영상물, 이런 음란물을 만들어서 조직적으로 유포하고, 제작하고, 이런 사람들이 IT 기술자들이었다는 거예요./n 이것을 어떻게 봐야 하는 겁니까?/n◆ 이청호:/n 그러니까 기본적으로 만든 기술자들의 윤리의식이 결여되었다고 볼 수가 있겠죠./n 그렇게 사용할 수 있는 기술을 알고 있는 사람이 먼저 윤리의식을 갖추어야 하는데, 그것이 잘 이루어지지 않았기 때문에 일어난 현상이라고 파악할 수 있을 것 같습니다./n◇ 노영희:/n 그런데 딥페이크 영상을 판매하고 제작하고 유포한 사람들 때문에 피해를 입은 여성 연예인들이 100명이 넘는다, 이런 이야기가 있던데요./n 이렇게 되면 실제 이들에 대한 처벌이나 이들의 행동을 제지할 수 있는 수단이나 이런 것들은 있습니까?/n◆ 이청호:/n 일단 법적으로 제지할 수 있는 수단이 있는 것 같습니다./n 미성년자의 경우에는 미성년 여자 연예인을 대상으로 이런 일을 벌였을 경우에는 아동·청소년의 성 보호에 관한 법이 있을 것 같고요./n 성인 여성 연예인을 대상으로 한 경우에는 성폭력 처벌 특별법이 있을 것 같습니다./n 그래서 이런 것들이 계속 너무나 그동안 처벌의 수위가 낮다고 비판이 많이 있었기 때문에 개정되고 있는 것으로 알고 있고요./n 그래서 3월 5일 날 통과된 법률이 6월 25일 날 시행될 거라고 예정하고 있는데, 이런 것에 의하면 특정 대상자의 의사에 반해서 특정 사람의 얼굴이나 신체, 음성을 편집하거나 합성을 하게 된다면, 5년 이하의 징역이나 5000만 원 이하의 벌금형에 처할 수 있게 됩니다./n 혹시 이것을 영리 목적으로 사용한다고 하면 7년 이하의 징역에 처해지는 그런 개정안이 시행될 것으로 생각됩니다./n◇ 노영희:/n 그렇군요./n 그런데 사실 저는 조금 걱정스러운 것 중 하나가 연예인들 얼굴이야 많이 알려져 있으니까 그것을 본 사람이나 유통하는 사람들이 이것은 누구 얼굴을 합성한 거야, 이것을 금방 알아낼 수 있겠지만, 예컨대 일반인의 얼굴을 이런 식으로 합성해서 범죄의 형식으로 이용한다면 그 해당 얼굴을 가진 피해자는 잘 모르잖아요?/n 본인 스스로도 자기 얼굴이 그렇게 쓰이고 있는 것을 모를 것이고, 또 그것을 본 사람들도 이 사람이 누구라고 하는 것을 정확히 잘 모를 거잖아요?/n 그러면 그 피해를 입은 사람이 그 피해를 입었다는 것 자체도 모르는 상황에서 그게 계속 돌아다니면서 더 큰 피해를 양산하고, 이런 식으로 갈 수 있는 거 아니에요?/n◆ 이청호:/n 그렇죠./n 그것은 기본적으로 인터넷이라는 공간이 익명성을 전제로 한 공간이고, 인터넷상의 거대한 공간이기 때문에 그 안에서 일어나는 것들을 모든 사람들이 다 알 수는 없죠./n ◇ 노영희:/n 그러니까 제가 거기서 또 하나 나아가서 생각해보면 그래서 만약에 예컨대 그런 딥페이크 음란물을 유포한 사람을 잡았어요./n 그러면서 그 증거로 경찰이 이거 네가 만든 거 아니냐고 하면서 영상물을 들이대요./n 그러면 맞다고 그 사람이 말을 합니다./n 그런데 이 얼굴은 누구를 대상으로 누구에게 피해를 입힌 거다, 라고 이야기를 했을 경우에 가해자, 혹은 범죄자가 그것은 내가 임의로 만든 건데요?/n 내가 그냥 없는 사람을 인조로 내가 알아서 조작해서 만든 건데요, 이게 누구에게 피해를 줍니까?/n 이런 식으로 말을 하게 되면 실제 피해자가 존재한다고 하더라도 그것을 처벌하기가 어렵지 않아요?/n 찾아내기도 어렵고./n◆ 이청호:/n 그것은 법적으로는 매우 복잡한 계산이 있을 것 같은데요./n 저는 윤리적인 시각에서 살펴보게 된다면, 우리가 뭔가를 만들고, 인터넷상에 그것을 공개를 한다는 것 그 자체만으로 이것이 무수히 많은 사람들에게 노출될 수 있다고 하는 가능성을 전제하고 있는 거라고 생각합니다./n 그렇기 때문에 그것을 만들고, 자기 혼자만 본다고 하더라도 그것이 디지털 공간상에서 공유가 되는 디지털 포맷으로 되어 있을 때는 그러한 가능성조차도 염두에 두어야 한다고 생각합니다./n◇ 노영희:/n 그렇군요./n 그리고 또 딥페이크의 부작용 중 하나가 합성 포르노 피해를 줄이기 위해서 포르노 영상을 모니터링하고, 잡아낼 수 있는 그런 기술이 없기 때문이다, 이런 이야기도 나오던데 맞습니까?/n◆ 이청호:/n 기술은 지금 많이 개발되고 있고요./n 미국 뉴욕대에서 포렌식 기술을 개발해서 딥페이크 영상이 제작될 때 생성되는 시점에서 지워지지 않는 그런 포렌식 정보를 거기에 입력하는 그런 방법이 있고요./n 그리고 페이스북에서도 문자, 음성을 바꾸는 기술을 사용해서 영상 속 사람이 말하는 입모양을 보고 이게 진짜인지, 가짜인지를 구별하는 기술도 개발한 것으로 알고 있고요./n 실제로 많이 있습니다./n 그런데 문제는 이것이 실제로 과학기술이 계속 발전하다 보니까 딥페이크를 만드는 사람들도 기술이 점점 정교화돼서 이것을 방지하는 기술을 적용되지 못하게 하는 기술 또한 발전할 수 있다는 거죠./n◇ 노영희:/n 그러니까 음란물을 딥페이크로 만들어서 유포하고, 그것을 잡아내는 기술도 있는데 또 잡아내는 기술을 방해하는 그런 기술을 또 사용해서 음란물을 계속 유포하고./n 이게 계속해서 악순환처럼 고리가 되어서 돌아가는군요?/n ◆ 이청호:/n 네./n◇ 노영희:/n 국회 법사위에서 이번에 N번방 처벌과 딥페이크 포르노 처벌을 혼동하는 사태가 벌어졌다고 하는데요./n 예를 들면 딥페이크가 일기장에 그림 같은 거다, 예술작품이다, 이런 이야기까지 나왔다고 하는데 이런 부분은 정확히 어떤 건가요?/n◆ 이청호:/n 일단은 기본적으로 그런 발언을 하신 분들이 과학기술, 인공지능 기술에 대한 지식이 부족하시기 때문에 그런 말씀을 하신 게 아닌가 하는 생각이 듭니다./n 왜냐하면 N번방이나 이런 것과 인공지능 기술이라고 하는 것이 전혀 다른 기술일 수 있거든요./n N번방 사용된 텔레그램이라고 하는 것은 어떤 SNS 메신저 기술이고요./n 그리고 딥페이크에 사용된 것은 인공지능인데, 이것이 결합된 것이기는 하지만 두 개가 전혀 다른 기술인데, 그것에 대한 사전지식이 부족하셔서 그런 언급을 하신 것으로 생각을 합니다./n◇ 노영희:/n 그런데 일기장의 그림이다, 이런 이야기는 왜 나온 거예요, 그러면?/n◆ 이청호:/n 그러니까 이것 또한 아까 말씀하신 것처럼 자신이 혼자 작업을 한 거라고 생각을 한 거겠죠./n 그러나 일기장에 그림을 그릴 때 그것이 혼자만 보는 거라고 하면 상관이 없지만 디지털 공간상에서 공개될 가능성이 있을 때는 그게 아주 큰 문제가 될 거라고 저는 생각을 합니다./n 그런 부분들을 잘 염두에 두어야 한다고 생각을 합니다./n◇ 노영희:/n 그러니까 합성하거나 영상물을 새로 만들거나 하는 과정 자체가 새로운 창작물의 수준이기 때문에 그것을 처벌하면 안 된다고 하는 식의 반론이 있었던 것인데, 그런 반론 자체가 잘못된 거다, 이렇게 보시는 입장이군요?/n◆ 이청호:/n 그렇죠./n 그것이 많은 사람들에게 공개될 가능성이 있기 때문에 단순히 혼자만 보는 게 아니라는 게 제가 말씀드리는 점이라고 할 수 있습니다./n◇ 노영희:/n 그렇군요./n 한국인공지능윤리협회에서 앞으로 우리 협회의 역할이나 이런 것이 저는 더 많아질 거라고 보는데, 성인 동영상이 일반인과 연예인을 합성하는 문제를 두고서 캠페인을 벌이고 있지 않습니까?/n 이거 어떤 겁니까?/n◆ 이청호:/n 실질적으로 딥페이크가 수년 전부터 사회적으로 많은 관심을 가져왔고, 많은 영상들이 제작되어 있었습니다./n 그래서 저희 협회에서는 이런 상황들을 보고서 이것이 윤리적으로 많은 문제를 일으킬 수 있다고 하는 판단에서 사람들이 서로 이 기술에 대해서 알고, 이 기술이 가진 위험성과 윤리적인 문제점들을 잘 알면 좋겠다고 하는 취지에서 그런 캠페인을 전개했습니다./n◇ 노영희:/n 협회 홈페이지에 들어가보면 캠페인의 구체적인 방식이라든가, 나쁜 딥페이크가 뭔지, 이런 예를 볼 수가 있겠네요?/n◆ 이청호:/n 아주 자세하게는 나와 있지 않지만, 자신이 어떤 것인지를 알고 서명하는 것을 통해서 운동에 동참한다고 하는 의식을 고취시키는 그런 방식으로 저희가 캠페인을 벌이고 있습니다./n◇ 노영희:/n 그리고 악의적 딥페이크에는 포르노 합성 말고, 가짜뉴스 살포도 있다고 하는데 그런 게 예를 들면 어떤 게 있을까요?/n◆ 이청호:/n 가장 유명한 것은 버즈피드라고 하는 매체에서 작성한 오바마 영상이 유명하다고 할 수 있겠죠./n 오바마가 비속어를 사용하면서 트럼프 대통령을 욕하는 영상이 있을 수 있겠고요./n 이것 외에도 많이 있을 수 있는데, 2018년에 멕시코에서 대선 기간 동안에 허위 뉴스를 딥페이크로 제작해서 살포한 경우도 있을 수 있겠고요./n◇ 노영희:/n 이제 마지막으로 과학의 날을 맞이해서요./n 과학윤리가 지켜지기 위해서 어떻게 해야 하는지 한 말씀만 짧게 부탁드릴게요./n◆ 이청호:/n 현대사회는 과학기술이 고도로 발달된 사회입니다./n 그렇기 때문에 과학기술과 인간의 삶을 떼려야 뗄 수 없는 그런 사회가 되었는데요./n 과학기술이 너무나 많이 빨리 발전하기 때문에 그것이 어떤 문제를 일으킬지에 대해서는 배워야 하는 그런 시점이 됐습니다./n 그래서 그런 사항들에 대해서 모든 사람들이 열린 관점을 갖고, 저와 같은 과학윤리전문가들이 노력을 해야 한다고 생각합니다./n◇ 노영희:/n 네, 그렇군요./n 오늘 말씀 여기까지 듣겠습니다./n 고맙습니다./n◆ 이청호:/n 고맙습니다./n◇ 노영희:/n 지금까지 이청호 한국인공지능윤리협회 회장이었습니다.