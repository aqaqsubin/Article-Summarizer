테러도 AI가 하는 세상, ‘제3의 전쟁혁명’ 온다
지난달 15일 미 공군 발표에 따르면 미국 플로리다주(州)에 있는 틴달(TIndal) 공군기지를 방어하는 임무를 맡은 325경비대에 최근 ‘ROBO-DOG’라는 로봇 군견이 전격 배치돼 정식 운영에 들어갔다. 진짜 군견처럼 ‘후각’은 없지만, 훌륭한 ‘시각’과 ‘청각’을 갖추고 미리 입력된 정보에 따라 자동으로 기능할 수 있는 반자율(semi-autonomous) 형태의 로봇이다.      이 로봇에는 모바일 카메라와 센서, 녹음기 등이 장착돼 있어 로봇이 보고 듣는 모든 시각 및 청각 정보가 관제센터에 전달된다. VR(가상현실) 헤드셋을 쓰고 해당 로봇을 통제하는 관제센터의 군인에게 고스란히 전달되는 것이다. 움직이는 로봇의 ‘눈’과 ‘귀’에 포착된 수상한 움직임을 실시간으로 감시할 수 있는 구조다.      이처럼 인공지능(AI) 기술은 최근 몇 년 사이 군사 분야에 확산하고 있다. 세계는 이미 인공지능을 활용한 무기 개발에 경쟁적으로 관심을 기울이고 있다. 미래 전쟁과 테러의 형식도 인간이 아닌 로봇에 의해 이뤄질 것으로 예상한다.       인공지능과 드론의 결합을 악용한 테러 가능성은 이미 현실이 되고 있다. 군사적으로는 미군이 무인기를 이용한 테러 용의자 공격이 아프간이나 이라크에서 일상화하고 있다. 테러리스트들도 드론을 활용한 테러를 시도하고 있다.          앞으로는 인공지능을 악용한 새로운 테러 양상이 우리에게 다가올 것으로 보인다. 무인자동차, 드론, 킬러로봇 등을 악용한 다양한 형태의 테러다. 인공지능 로봇으로 사람들이 많이 모이는 다중이용 시설과 장소를 공격하거나, 바이오 테러도 가능할 것으로 전망된다.      더 우려되는 것은 로봇이 해킹을 당하는 경우다. 해킹당한 로봇은 자살폭탄 기계나 마찬가지로 치명적이다.       또 ‘외로운 늑대’처럼 ‘외로운 로봇’의 공격도 일어날 수 있다. 가령 더 고도화된 인공지능을 갖춘 드론, 자동차, 그리고 킬러로봇 등에게 테러학습을 시킨 뒤에 고성능 화생방 무기로 공격하도록 사주할 경우다. 정말 이런 일이 발생하면 대응할 방법이 묘연하다.        문제는 지금은 공격 목표를 무인기에 입력하는 방식을 취하고 있지만, 머지않은 장래에는 로봇이 입력된 특정인의 얼굴이나 신체적 특성을 가진 표적 인물을 발견해 곧바로 공격할 수 있게 된다. ‘인공지능 솔저’가 등장한다는 것이다.       더구나 로봇 무기가 암시장에서 거래되거나 테러리스트 손에 들어가는 것도 시간문제다. 그래서 최근엔 AI 무기가 핵무기와 달리 비싸지 않고 원재료를 구하기도 쉬워지고 있다. 칼라시니코프(AK-47) 소총처럼 대량생산되어 세계 곳곳에서 사용할 것이란 우려가 나온다. 가히 전쟁과 테러수단 패러다임의 획기적인 변화라 할 수 있다.        AI 기술은 이제는 ‘빠른 계산’을 넘어 ‘자체적인 사고와 학습’으로 급속히 진화 중이다. 더구나 컴퓨터와 뇌과학 기술이 발전하면서 AI 산업 또한 크게 확대하자 우려의 목소리가 높아지고 있다.       지난 2015년 7월 28일 아르헨티나 부에노스아이레스에서 열린 ‘국제인공지능 콘퍼런스(IJCAI)’에서는 스티븐 호킹 박사와 놈 촘스키 등 2,500명이 넘는 인공지능, 로봇공학 연구가들이 인공지능 무기에 반대하는 성명서를 내기도 했다.         이 성명서는 주요 군사국가가 인공지능 무기 개발을 시작하면 전 세계 인공지능 무기 군비경쟁은 불가피할 것으로 전망하고 있다.       또한 인공지능 무기는 핵무기와 달리 비용이 비싸지 않고, 대량생산이 가능하기에 더 위험하다고 경고하고 있다. 핵무기와 비교해 가격이 상대적으로 싸고 구하기도 어렵지 않아 AK 소총처럼 대량 생산되어 전 세계에서 사용되게 될 것이라는 경고다.       이렇게 될 경우 암시장에서 테러리스트에게 거래될 수 있고, 독재자나 군부가 인종학살에 인공지능 무기를 이용할 수 있다고 성명서는 우려하고 있다. “인공지능 무기는 암살, 국가전복, 국민탄압, 그리고 특정 민족 학살의 임무를 수행하는 데 최적의 수단”이라는 게 성명서의 지적이다.       그래서 인공지능 무기가 경쟁적으로 생산되면 암시장을 통해 국민을 통제하려는 독재자, 소수인종을 청소하려는 군벌, 테러리스트의 손에 인공지능 무기가 들어가는 게 시간문제라는 것이다.        AI 무기 발전이 화약과 핵무기를 이은 제3의 전쟁혁명으로 이어져 인공지능 무기가 초래할 수 있는 재앙에 대한 경고도 있다. 따라서 인공지능이 인류의 삶에 위대한 공헌을 할 수 있도록 해야 하며, 이에 반하는 인간의 통제를 받지 않는 인공지능 무기의 개발 및 활용을 금지해 새로운 군비경쟁을 막아야 한다.         그래서 최근 미국 국토안보부는 ‘사물인터넷 보안을 위한 전략적 원리’라는 성명서를 발간했다. 현재의 인공지능, 사물인터넷 보안의 위험을 경고하고, 이에 대한 안보적 측면의 대비책을 촉구했다.      전문가들의 우려 속에서도 로봇 및 인공지능 무기의 연구・개발은 활발히 진행되고 있다. 미 국방부는 전 세계에서 로봇 연구에 가장 많은 지원을 하는 기관 가운데 한 곳이지만, 사람의 통제를 받지 않는 인공지능 무기엔 반대하고 있다.       영국은 무기용 로봇연구・개발에 있어 미국보다 더 엄격한 규정을 가지고 있었으나, 최근 이 규정에 반대하는 목소리가 높아지고 있다. 그러나 미국과 경쟁적으로 인공지능 무기를 개발 중인 중국과 러시아는 로봇이 자율적으로 인간을 살상하는 문제에 크게 반대하지 않는 입장이다.      기업들도 군사용 인공지능 로봇에 우려가 크다. 일런 머스크 테슬라모터스 최고경영자(CEO)는 인공지능을 ‘악마’에 비유, “우리는 악마를 소환하고 있다”고 말했다. 스티브 워즈니악 애플 공동 창업자는 “인공지능 무기가 발전하면 화학, 핵무기에 이은 ‘제3의 전쟁혁명’이 될 수 있다”며 군사적 사용을 금지하는 국제협약 마련을 촉구했다.      과학자들은 2045년을 기술적 특이점(technological singularity)으로 예상한다. 이때가 되면 인공지능이 인간지능을 초월하게 된다는 예언이다. 이는 인공지능이 스스로 진화하면서 미래가 인간이 예측할 수 없는 시점에 이를 수도 있다는 우려다.       물론 단정적으로 말할 수는 없지만, 인공지능과 같은 기술이 지속해서 발전하면 대변혁을 경험할 수밖에 없다는 것은 자명하다. 컴퓨터가 인간을 지배하는 시대가 공상과학 영화 속의 가상현실이 아니라 바로 우리 눈앞의 현실로 다가온다는 암울한 미래다.      따라서 우리 역시 AI를 악용한 테러 방지를 위해 기술적 능력 배양, 법률·제도적 장치 마련, 그리고 국제협력 등을 모색하고 대비할 필요가 있다. 주변국들의 미래 상황과 미래전 대응전략을 파악하는 것도 매우 중요하다.      이만종 한국테러학회 회장·호원대 법·경찰학부 교수  ▶ ▶ ▶ ⓒ중앙일보(https://joongang.co.kr), 무단 전재 및 재배포 금지
중앙일보
