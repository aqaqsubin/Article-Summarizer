[팩플] 에어비앤비 AI가 "당신의 위험 점수"를 매기겠다면?
"에어비앤비의 불투명한 AI를 조사하라."      미국 비영리단체 전자개인정보보호센터(EPIC)는 지난달 26일 미 연방무역위원회(FTC)에 요청했다. 에어비앤비의 고객 '위험 평가(risk assessment)' 기술과 고객 평가 알고리즘이 투명하지 않고, 공정성에도 문제가 있다는 이유다.              -에어비앤비가 투숙객과 집주인의 ''를 매기고, 이 과정에서 ''을 쓰는 게 문제라는 주장이다. 경제협력개발기구(OECD)의 AI 원칙(인간 중심 가치와 공정성)과 FTC 법 5조(불공정한 경쟁방법 금지)를 위반했다는 것.      -EPIC이 지적한 알고리즘은 에어비앤비가 가진 인공지능(AI) 를 기반으로 한다.      -특허받은 AI 알고리즘은 소셜네트워크(SNS)·검색엔진·블로그 정보를 수집·분석해 이용자의 신뢰도에 점수를 매기고, 성격과 행동 특성에 따라 몇가지 유형으로 분류한다.      -AI가 당신을 '신경질적', '자기애적','사이코패스', '마키아벨리즘(목적지상주의)', '반사회적', '개방적' 등으로 평가할 수 있다는 것.       -EPIC은 "특정 인종이나 소수자 박해 등에 악용될 소지가 있다"고 경고했다.      -에어비앤비가 임의로 사용자의 (이름, 이메일, 전화번호, 생일, 거주지, 고용기록, 학력, 금융정보, IP 기록 등)을 수집하고 자의적으로 평가할 수 있기 때문이다.     -에어비앤비가 보기에 사고 위험이 높은 사용자는 숙박 예약을 못할 수 있다는 의미다. 영화 '마이너리티리포트'처럼 실제로는 위험 행동을 하지 않았음에도 AI가 위험인물로 예측한 데이터를 근거로 누군가의 권리를 박탈할 수 있는 것.     -이 AI 알고리즘이 데이터 수집을 으로 하는지, 을 담보할 수 있는지, 이 없는지 등도 논란이다.       -에어비앤비 이용 중에 일어나는 강력범죄를 예방하겠다는 이유다.      -2019년 10월 미국 캘리포니아주에서 에어비앤비 투숙객이 파티를 열다 총격 사건이 발생해 5명이 사망했다. 2017년엔 미국 미네소타주에서 투숙객이 집주인의 딸을 대상으로 성범죄를 일으켰다. 문제가 도마에 올랐다.     -에어비앤비는 2017년 AI 스타트업를 인수했다. SNS 등 온라인 정보를 수집·분석해 개인의 평판과 특성을 평가하는 기술 기업이다.     -트롤리 기술을 기반으로 에어비앤비는를 2018년 11월 미국에서 취득했다. 유럽특허청에도 해당 특허 심사를 요청한 상태다.         -에어비앤비는 범죄정보 조회(미국 등 정보공개 국가에 한정)를 통해 이용자를 검증하고 있다. 에어비앤비 웹사이트에는 "예약 확정 전 위험 점수를 매기고, 예상적 분석과 머신러닝을 이용해 사건을 예방한다"고 공지돼 있다.    -찰리 어바니치 에어비앤비 대변인은 ""라고 밝혔다. 실제 알고리즘 적용 여부에 대해선 공개하지 않았다.     -에어비앤비 코리아 관계자는 ""라며 "향후에도 그런 알고리즘을 적용할 계획이 없는 것으로 안다"고 답했다.        -를 지적하는목소리가 높아지고 있다. 미국에선 승차공유 업체 우버(Uber) 관련 성범죄만 연간 3045건(2018년 기준) 발생했다.    -미국 안보 기관, 경찰, 보험사 등은 AI 및 머신러닝으로 특정 인물의 위험도를 분석해 이미 활용 중이다.      -소프트웨어정책연구소 AI 정책연구팀 은 "이용자 신뢰도가 중요한 보험, 금융, 공유 경제 영역에선 AI를 이용한 개인 평가가 조용히 이뤄지고 있었다"며 "최근 들어 글로벌 IT 기업들과 유럽연합(EU)가 개인 프라이버시 문제에 주목하면서 AI 윤리에 대한 논쟁이 활발해지는 단계"라고 말했다.      정원엽 기자 jung.wonyeob@joongang.co.kr    ▶ ▶  / ⓒ중앙일보(https://joongang.co.kr), 무단 전재 및 재배포 금지
중앙일보
