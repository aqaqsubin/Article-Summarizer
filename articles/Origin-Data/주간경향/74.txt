[알아두면 쓸모있는 과학](16) 진짜 같은 가짜 영상 만드는 ‘딥페이크’
피해자를 협박해 음란 동영상을 찍게 한 뒤 이를 공유한 n번방 운영자 조주빈이 경찰에 체포됐습니다. “멈출 수 없던 악마의 삶을 멈춰줘서 감사하다.” 조씨가 검찰에 송치되면서 남긴 말입니다. ‘그들’은 피해자들을 성착취한 영상을 한낱 유흥거리로 즐겼습니다.가까운 친구가 가해자로 둔갑하기도 했습니다. 가해자는 지인의 영상을 음란물과 합성했습니다. 이렇게 만들어진 ‘지인 능욕 영상’을 n번방에 공유한 것으로 알려져 있습니다. 이 영상을 만드는 데 사용된 기술은 최근 사회문제로 대두되고 있는 ‘딥페이크(deepfake)’입니다. 인공지능을 이용해 디지털 영상을 감쪽같이 위조하는 기술입니다.미국 매사추세츠공대가 발행하는 기술분석 잡지 〈MIT 테크놀로지 리뷰〉는 지난해 초 가장 조심해야 할 인공지능의 위험요소 중 하나로 딥페이크 기술을 지목했습니다. 사람이 정보를 조작하는 수준을 넘어 인공지능의 힘을 빌려 진짜 같은 가짜 정보가 범람하는 세상이 올 수 있다는 이유에서였습니다. 일각에서는 딥페이크 기술의 발전으로 ‘진실의 종말’ 시대가 올 것이라는 비관적 전망도 내놓고 있습니다.딥페이크란 AI 기술인 딥러닝의 ‘딥(deep)’과 가짜라는 뜻의 ‘페이크(fake)’를 합친 단어입니다. 특정 인물의 얼굴과 신체 부위를 전혀 다른 영상과 합성하기 위해 딥러닝이라는 AI 기술과 안면 매핑(facial mapping), 안면 스와핑(face-swapping) 기술을 복합적으로 이용합니다.딥페이크는 ‘생성적 적대 신경망(GAN)’이라는 AI 기술이 세상에 나오면서 등장했습니다. GAN은 이미지의 진위를 판단하는 ‘감별자’ 알고리즘과 이미지를 만들어내는 ‘생성자’ 알고리즘을 대립시켜 영상을 조작하는 원리입니다. AI는 대립을 통해 원본과 조작 영상물의 오차를 최대한 줄여나갑니다. 화폐 위조범과 경찰에 비유해볼까요. 위조범이 만든 가짜 화폐를 경찰이 단속합니다. 그러면 화폐 위조범은 더욱 정교하게 가짜 화폐를 만들게 됩니다. 경찰도 더욱 고도화된 수사기법으로 가짜 화폐를 적발해냅니다. 둘은 쫓고 쫓기는 경쟁을 하고 이 과정에서 가짜 화폐는 점점 고도화됩니다. 딥페이크를 통한 가짜 영상도 이와 비슷한 원리를 따릅니다.가짜 이미지 제작 기술은 오래전부터 있었습니다. 과거 이미지는 수작업으로 편집됐기 때문에 확대하면 조작한 티가 났습니다. 그런데 영상편집 기술이 AI 기술인 GAN과 만나자 진짜와 가짜를 감별해내기가 어려워졌습니다. AI는 합성하고자 하는 얼굴의 모습이나 표정이 다르더라도 알아서 자연스럽게 합성해주기 때문입니다.딥페이크는 누구나 손쉽게 사용할 수 있는 기술이라는 점에서 위협적입니다. 딥페이크는 프로그래밍 소스가 공개돼 있습니다. 일정 수준 이상 프로그래밍 언어를 구사할 수 있는 사람이라면 가정용 컴퓨터로도 영상을 조작할 수 있습니다. 프로그래밍 언어를 모르더라도 조작된 영상을 바로 내려받을 수 있는 웹사이트까지 등장했습니다. 마음만 먹으면 영상을 손쉽게 만들어낼 수 있는 것입니다. 가짜 영상을 만들어 범죄로까지 악용할 수 있는 기술이 대중화되는 아이러니가 발생한 것입니다.GAN 기술은 날로 발전해 지난해에는 사진 한 장으로 동영상을 만들어내는 기술도 나왔습니다. 삼성전자와 모스크바 AI연구소는 사진 단 한 장만으로도 말하는 얼굴 동영상을 만들어낼 수 있는 신기술을 발표했습니다. 국내외에서 목소리를 위조하는 기술도 연구 중입니다.물론 딥페이크 기술은 잘만 활용되면 큰 이점을 가져다줄 수 있습니다. 그러나 이 기술이 악용될 때가 문제입니다. 가장 큰 우려는 누구도 무엇이 진짜인지 가짜인지 구별해낼 수 없다는 데 있습니다. 딥페이크가 더욱 확산되면 자신이 본 영상이 진짜인지 가짜인지 확신할 수 없게 될 것입니다. 특히 ‘사악한 속임수’를 의도하고 딥페이크 영상을 유포할 경우 개인의 사생활 침해는 물론 여론 조작까지 가능합니다. 딥페이크 영상은 국가안보 분야에서도 위협적인 요소로 거론됩니다.실제 딥페이크로 제작된 가짜 영상이 인터넷상에서 논란이 된 사례가 많이 있습니다. 미국의 뉴미디어인 버즈피드는 오바마 전 미국 대통령이 “트럼프는 정말 쓸모없는 사람”이라고 말하는 영상을 게시했습니다. 이 영상은 딥페이크 영상의 파급력을 알리기 위해 오바마 전 미국 대통령과 코미디언의 목소리, 얼굴 모습을 합성한 가짜 영상이었습니다.낸시 펠로시 하원의장도 딥페이크 영상 때문에 곤욕을 치렀습니다. 영상 게시자는 영상의 재생 속도를 의도적으로 조절했습니다. 그 결과 마치 낸시 펠로시 의장이 혀가 꼬여 말을 잘 못 하는 것처럼 보였습니다.우리나라에서는 딥페이크로 조작된 음란 동영상이 특히 큰 문제가 되고 있습니다. 앞서 언급한 지인능욕방에 공유된 수많은 동영상이 대표적 사례입니다. 딥페이크로 만들어진 가짜 동영상이 얼마나 많은지 전 세계에 유통 중인 딥페이크 영상의 25%가 한국의 여성 연예인 영상과 합성된 것이라는 소름끼치는 조사 결과까지 나온 상황입니다.딥페이크로 인한 피해자가 늘면서 개선의 목소리 또한 커지고 있지만 갈 길은 멉니다. 먼저 국내에는 딥페이크 규제 법안이 전무합니다. 지난해 10월 국회입법조사처에서 발표한 보고서는 “국회에 허위정보에 대한 법안 20여 건이 제출돼 있지만 딥페이크에 대한 대응은 부재한 상황”이라며 “딥페이크는 기존의 허위정보와는 차원이 다른 위험성을 내포하므로 기술적 정책적 노력이 필요하다”고 지적했습니다.해외에서는 딥페이크를 막기 위한 탐지 기술 개발이 한창입니다. 미국은 국방부 산하 방위고등연구계획국(DARPA)에 미디어포렌식(MediFor) 팀을 구성해 딥페이크 콘텐츠를 확인하는 도구를 개발하고 있습니다. 딥페이크 영상이 눈 깜박임이 없다든지, 조명의 일관성이 없는 특징을 이용해 탐지하는 기술도 개발 중입니다.그런데 딥페이크 탐지 기술이 가짜 영상을 모두 잡아낼 수 있을까요? 탐지 기술이 고도화되면 딥페이크를 이용한 조작 기술도 고도화될 것입니다. 앞서 언급한 쫓고 쫓기는 전쟁이 벌어지는 것이죠. 그 사이 영상으로 인한 피해는 고스란히 피해자와 영상으로 거짓 정보를 습득한 대중의 몫으로 남을 것입니다. AI라는 눈부신 과학기술이 인간의 거짓과 탐욕에 악용되는 현실은 참으로 씁쓸합니다. 현실 앞에서 우리가 제일 먼저 갖춰야 할 것은 거짓 동영상을 보더라도 이 영상이 진실인지 가짜인지를 비판적으로 생각해보는 미디어 리터러시 능력일 것입니다.목정민 과학칼럼니스트© 주간경향 (), 무단전재 및 재배포 금지〈경향신문은 한국온라인신문협회(www.kona.or.kr)의 디지털뉴스이용규칙에 따른 저작권을 행사합니다.〉
주간경향
