[기고] 자율주행시대, AI 판단 믿을 수 있을까?
2020년이 밝았다. 지금의 3040세대에게 2020년이라는 말은 ‘원더키디’라는 만화와 연결되어 떠오를 것이다. 그 만화처럼 하늘을 나는 자동차가 나오지는 않았지만 이제 AI(인공지능)기술로 자동차가 스스로 도로를 운전하는 자율주행시대는 코앞이다.  자율주행자동차의 운전주체가 사람이 아닌 AI로 넘어가면 AI의 자율적 의사결정 범위가 넓어지는 건 필연이다. 많은 이들이 AI 시스템 오류로 인한 교통사고를 우려하는 이유다. 2016년 구글 Waymo는 차선 변경 도중 옆 차로의 버스가 양보할 것이라고 잘못 판단해 충돌했고, 테슬라 모델S의 경우 흰색 트레일러를 빛나는 하늘로 인지하면서 인명사고를 일으켰다. 지난 12월에는 비상등을 켜고 정차 중이던 경찰차를 자율주행자동차가 들이받는 사고를 일으켰다.   교통사고의 90%가 사람의 실수나 부주의에 의해서 발생한다는 사실을 알면 놀랄 일은 아니다. 오히려 자율주행이 완벽하게 자리 잡는다면 운전자 실수로 인한 사고를 크게 줄일 수 있다는 이점이 있다. 단순 계산으로 연간 3000명 이상을 살리고 약 20조원의 경제적 손해를 막을 수 있다.  이제 우리 앞에는 자율주행자동차 상용화에 앞서 준비할 사항이 산재해 있다. 현행 도로교통법과 차원이 다른 법적, 제도적 장치 마련이 시급하다. 사람과 AI 중 누구를 운전자로 볼지, 운전면허를 누구에게 부여할지, 자율주행 중 사고가 난 경우 책임은 누가 지고 어떻게 물을지 등에 대한 명확한 기준이 필요한 시점이다.  딜레마 상황에서 AI가 인간 생명에 대한 판단을 할 가이드라인을 마련하는 것도 중요 과제다. 자율주행 운전 중에 앞차와 충돌을 피하기 위해 급히 핸들을 꺾어야만 할 때, 왼쪽에 어린이가 탑승한 차량이 있고 오른쪽에 오토바이 배달부가 있다면 AI는 어떤 선택을 해야 할까? 이는 자율주행 AI의 판단과 결부해 항상 언급되는 ‘트롤리 딜레마’와 다름없다. 다수를 살릴 수 있다면 소수를 희생할 것인지, 생명의 경중을 AI가 판단할 수 있는지 등에 대한 기준은 여전히 어려운 과제다.  가장 중요한 건 ‘윤리’라고 믿는다. 윤리란 인간이 사회의 일원으로서 지켜야 할 행동규범으로 도덕적인 성향과 더불어 법률적 성향을 동시에 가진다. 자율주행자동차가 상용화되기 위해선 국제적으로 통용할 수 있으면서 한국의 교통상황에 적합한 자율주행 윤리·법제적 가이드라인의 개발이 선행되어야 한다.  도로교통공단도 시대에 발맞춰 한국형 자율주행 가이드라인 발전에 힘을 쏟고 있다. 그 일환으로 지난해 8월부터 약 4개월간 ‘자율주행자동차 상용화 대비 한국형 윤리·법제 가이드라인 및 지침 연구’라는 정책연구를 진행했다. 당시 가장 크게 다가온 건 윤리 가이드라인 근간에는 생명존중과 인간 존중이 최우선해야 한다는 점이었다. ‘사람과 생명’이 안전한 교통안전 환경 조성에 앞장서야 함을 다시 한 번 천명한 것이다.  자율주행과 관련한 윤리 가이드라인은 AI뿐 아니라 관련 이해 관계자까지 수범자의 범위 확장이 필요하다. 자율주행자동차의 사용자, 제조자, 타 교통참여자, 도로 및 시설관리자는 윤리적 원칙에 따라 생명을 우선적으로 보호하며 자율주행자동차가 안전히 운행할 수 있도록 돕는 윤리의식이 요구된다. 도로교통공단은 ‘생명 존중’이라는 큰 원칙 하에, 국내 입법 적용과 함께 국내 도로교통법규와 교통상황에 맞는 한국형 자율주행 가이드라인을 구축하고 교통 대변혁의 자율주행시대의 컨트롤타워 역할을 해나가도록 준비할 것이다.   윤종기 도로교통공단 이사장ⓒ 세상을 보는 눈,
세계일보
