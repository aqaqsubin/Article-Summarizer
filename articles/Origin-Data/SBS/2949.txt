[취재파일] AI에 의한 입시부정?…"학력 평가 알고리즘"에 뿔난 영국 학생들
지난 8월 13일 영국의 고등학교 학력평가 결과인 A레벨 점수가 통보되자 잉글랜드와 웨일즈, 북아일랜드 지역 30만 명의 대입 지망생들이 반발하고 나섰다. 통상 인공지능(AI)이라고 표현되는 컴퓨터 알고리즘이 산정해 통보한 점수가 학교에서 자체 평가한 점수보다 훨씬 낮게 나왔기 때문이다.세계적인 코로나19 대유행 속에서 가장 심각한 타격을 입은 국가 가운데 하나인 영국은 올여름 A레벨 테스트를 시행할 수 없게 되자 컴퓨터 알고리즘을 이용해 성적을 산정했다. 영국 교육 당국이 선정한 컴퓨터 알고리즘 다이렉트센터 수행평가 모델(Direct Center Performance Model)은 여러 가지 데이터를 기반으로 학점을 도출하도록 설계됐다.학생들과 전문가들은 이 알고리즘이 상대적으로 불우한 학생들에게 불리하게 학점을 산정했다며, 학점 산정 알고리즘에 대한 철저한 조사를 촉구하고 나섰다.대입 지망생인 18살 필립(Philip)의 경우 웨스트 런던 스쿨의 교사들이 2과목은 A, 1과목은 B 학점을 받아 엑시터대학(Exeter University)에 충분히 입학할 수 있을 것으로 예상했지만, 알고리즘이 산정해 통보한 점수는 1과목 B, 2과목 C학점 이었다. 엑시터대학에 입학할 수 없게 된 것이다.잉글랜드의 학생 가운데 40%가 필립처럼 교사가 예측한 학점보다 낮은 학점을 받았다. 특히 사립학교 학생보다 정부의 지원을 받는 주립학교의 학생들이 훨씬 낮은 점수를 받았고, 결국 원하는 대학의 입학허가를 받지 못할 처지가 됐다.강력한 반발이 이어졌고, 영국 교육부 앞에서는 10대 학생들이 항의 시위를 벌였다. 학생들은 "* 같은 알고리즘 집어치워!"라고 외쳤다. 파문이 계속되자 가빈 윌리엄슨(Gavin Williamson) 영국 교육부 장관은 알고리즘이 산정한 학점이 아닌 교사들이 예측한 학점을 인정하도록 하겠다고 발표했다.영국 교육 당국이 이용한 알고리즘은 2020년 지망생이 직전 학년도 학생들과 유사한 학점을 받도록 최고 학점과 최저 학점의 분포를 조정해 공정성을 높이려고 채택한 것이었다. 교사들이 예측한 학생들의 점수와 순위를 반영해 학점을 산정하는 방식이었다. 문제는 알고리즘이 학교의 과거 입시 성적을 반영하도록 했고, 이것이 부유한 환경의 학생들에게 유리한 점수 부여로 이어졌다는 것이다.학부모들이 학비를 부담하는 영국의 사립학교들은 보통 학생 수가 적고, 특정 모델로 표준화하기 힘든 점수 분포를 가지고 있었다. 이에 따라 부유하고 백인들이 많은 사립학교 학생들은 교사가 예측한 학점에 더 많은 비중을 두도록 알고리즘을 변경했다.옥스포드대학 컴퓨터공학과 수석 연구원 헬레나 웹(Helena Webb)은 "문제는 공정성 문제를 해결하는 알고리즘은 여러 가지가 있을 수 있다는 것입니다. 학교 당국의 발표대로 지난해와 비슷한 결과를 얻도록 설계할 수 있고, 이런 방법이 전국적인 단위에서는 공정하다고 할 수도 있습니다. 하지만 개개인에 대한 공정한 점수와는 완전히 다른 결과를 낳을 수 있습니다. 알고리즘은 작년에 발생한 상황을 그대로 반영합니다. 그렇기 때문에 올해 학교의 실적이 개선될 수 있다는 것을 반영하지 못합니다. 그래서 주립 학교 학생들은 과거에 높은 학점을 받아온 유명한 사립학교 학생보다 불리한 점수를 받게 되는 것입니다."라고 말한다.학교 자체 평가에서 A플러스 2과목과 A학점 1과목으로 예측됐지만 3과목 모두 A학점을 받은 서잉글랜드의 치펀햄(Chippenham) 학교 18살 조쉬 윅스(Josh Wicks)는 "화가 나는 것은 주립 학교를 대하는 태도입니다. 알고리즘은 학교가 작년에 높은 점수를 받지 못했다고 학생들도 올해 좋은 점수를 받지 못할 것이라고 생각합니다."라고 말했다. 소셜미디어와 비자 신청, 얼굴 인식, 그리고 시험점수 산정 등 알고리즘은 우리 사회 대부분에서 광범위하게 이용되고 있다. 새로운 기술은 재정이 부족한 정부나 혁신을 추구하는 회사에는 하나의 탈출구가 될 수 있다. 하지만 전문가들은 오래전부터 알고리즘의 편향성에 대해 경고해 왔고, 자동화가 확산함에 따라 알고리즘에 대한 우려도 커지고 있다.디지털 기술의 남용 문제를 다루는 팍스글로브(Foxglove)의 공동설립자 코리 크라이더(Cori Crider)는 "A레벨 테스트 문제는 빙산의 일각에 불과합니다. 알고리즘은 사용된 원 데이터에서 발견된 편향성을 그대로 반영합니다."라고 말했다. 크라이더는 기술만을 비난하는 것은 경계해야 한다며 다음과 같이 지적했다."그것이 기술의 문제라고 말하는 사람은 거짓말을 하고 있는 것입니다. 영국의 시험에서 문제가 된 것은 학점 인플레이션을 최소화하기 위해 정치적인 선택을 했다는 것입니다. 그것은 기술의 문제가 아니라 정치적인 선택의 문제입니다."팍스글로브와 이민자복지협의회는 최근 비자 업무를 처리하는 영국 내무부의 알고리즘에 문제를 제기했다. 이들은 알고리즘이 특정 국가 출신의 비자 신청에 대해 편향성을 가지고 있고, 이들의 비자 발급을 거부하도록 하고 있다고 지적했다. 팍스글로브는 영국의 비자 선별 시스템이 과거 편향성과 차별을 컴퓨터 프로그램에 주입해 편향성과 차별을 더욱 강화하고 있다고 주장한다.영국 내무부는 "비자 처리 시스템이 어떻게 작동하고 있는지를 살펴보고 있으며, 더 안전하고 정제된 시스템을 만들기 위해 처리 과정을 다시 디자인하고 있습니다. 하지만, 이민자복지협의회의 주장은 받아들일 수 없습니다."라고 밝혔다. 크라이더는 과거의 데이터가 알고리즘의 편향성으로 이어진다는 것은 다른 분야에서도 명확하게 확인할 수 있다며, 미국 경찰의 예측 단속 시스템도 마찬가지라고 말한다.지난 6월 캘리포니아주의 산타 크루즈시는 경찰관들이 사용하는 예측 단속 시스템 소프트웨어가 유색인종을 차별할 우려가 있다며 시스템 사용을 금지했다. 저스틴 커밍스(Justin Cummings) 시장은 "우리 사회에 유색인종 시민들을 겨냥할 수 있는 기술이 있습니다. 이것은 우리에게 필요 없는 기술입니다."라고 말했다. "문제는 입력되는 데이터입니다. 과거 데이터가 알고리즘에 투입되고, 그 데이터에 존재하는 편향성이 알고리즘에 반영되는 것입니다."라고 크라이더는 말한다.옥스포드대학 컴퓨터공학과 수석 연구원 헬레나 웹(Helena Webb)도 같은 문제를 지적한다."문제가 되고 있는 것은 알고리즘이 학습하는 과거 데이터입니다. 여러 얼굴 인식 기술이 나왔는데, 문제는 이 시스템들이 백인, 특히 백인 남성들의 얼굴로 학습한다는 사실입니다. 그래서 현장에 적용된 시스템들이 백인 남성의 얼굴 인식은 잘하지만, 여성 특히 유색인종 여성의 얼굴인식은 잘하지 못합니다. 알고리즘에 입력되는 데이터 자체와 데이터 입력 방식에서 문제가 발생하는 것입니다."웹은 이런 문제들은 입력하는 데이터 셋을 다양화하고, 알고리즘에 보다 다양한 사람들의 의견을 반영하는 것이 필요하다고 말한다.전문가들은 영국의 학력 평가 알고리즘에 대한 논란이 기술에 대한 감독의 강화로 이어지기를 바라고 있다. 새로운 AI(인공지능) 시스템에 대한 제도적 감독이 부족하다는 지적이다.인스타그램의 CEO 아담 모세리(Adam Mosseri)는 "일부 기술들은 우리 사회에 존재하는 편견을 그대로 반복할 위험이 있습니다. 우리의 상품과 서비스에 편향성이 없도록 하는 노력과 함께, 우리가 만든 시스템을 면밀하게 검토해서 편향성을 제거할 필요가 있습니다."라고 말했다. 인스타그램의 모회사인 페이스북은 최근 시스템의 편향성 점검을 담당하는 팀을 만들었다.자동화된 시스템은 요즘 여러 부문에서 다양한 방법으로 우리의 삶을 결정하고 있다. 크라이더는 "일상생활에서 알고리즘이 사용되지 않는 분야가 있는가?"라고 반문하면서 알고리즘의 사용에 대한 반대 운동이라도 나타났으면 좋겠다고 말한다.미국 CNN 방송은 과거 데이터를 기반으로 하는 알고리즘은 과거 데이터에 존재하는 편향성을 강화해 불평등을 심화한다고 보도했다. 영국의 알고리즘 학력평가 파동은 이런 알고리즘의 부작용을 그대로 보여준다는 것이다.영국 정부가 알고리즘이 산정한 점수나 학교 자체적으로 산정한 점수 가운데 하나를 대학 입시에 활용하도록 함으로써 코로나19가 초래한 '알고리즘 학점' 논란은 일단락됐다. 하지만 코로나19로 비대면 활동이 늘면서 컴퓨터 알고리즘에 의한 자동화 시스템은 더욱 광범위하게 우리 일상 속으로 파고들고 있다. 나도 모르는 사이에 편견에 사로잡힌 인공지능이 나를 평가하고 나의 일상을 조정하고 있는지 모른다.   (사진=게티이미지코리아)    김용철 기자(yckim@sbs.co.kr)
SBS
