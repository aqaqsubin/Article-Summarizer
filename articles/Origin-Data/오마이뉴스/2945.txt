확산되는 디지털 성범죄, 지체되는 구조적 예방장치
[오마이뉴스 정진아·오서영 기자]3월 8일은 세계여성의날이었다. 낙태죄를 폐지하는 등 여성의 권리가 신장되는 조짐이 보이고 있지만, 인터넷상에선 나날이 교묘한 방식으로 발전하는 여성의 성상품화와 성범죄가 만연하다. 여성이 성범죄로부터 안전한 세상을 만들어가기 위해서는 아직 변해야 할 것들이 많이 남아있다. '이 계정 신고 부탁드립니다.' 해당 문구와 함께 트위터 상에 꾸준히 올라오는 게시물이 있다. 이는 '지인 능욕(지인의 얼굴 사진을 음란 사진에 합성해 유포하는 행위)'의 이름을 단 계정이다. 게시물에는 자신 또는 지인의 사진이 음란물에 합성된 채 다수 올라와 있다는 내용이 담겨 있다. 계정에는 피해자의 개인 정보가 함께 기재된 경우도 많다. 다수의 사용자들이 해당 계정을 신고하면 계정이 정지 또는 삭제 처리된다. 그러나 SNS 상에서의 처벌에 그칠 뿐 법적 처벌로 이어지는 경우는 별로 없다. 가해자의 계정이 해외 SNS 계정이라 추적이 어렵다며 경찰이 피해자의 신고를 받지 않는 경우가 많기 때문이다. 2019년 12월 서울시에서 발표한 자료에 따르면 디지털 성범죄의 직접적 피해자 중 66.6%가 아무 대응을 하지 않았다. 처벌의 불확실성(43%)을 이유로 꼽은 피해자가 가장 많았고, 번거로운 대응 절차(37%)와 대응 방법 모름(35%), 피해 사실이 알려지는 것에 대한 두려움(31%) 등도 이유로 꼽혔다. 가해자는 쉽게 새로운 계정을 만들어 사진과 영상을 재유포하기도 한다. 피해자는 가해자의 SNS 계정이 사라져도 자신의 얼굴이 합성된 사진 또는 영상이 다른 곳에 유포되었을 수 있다는 공포에 시달린다. 위의 사례 외에도 다양한 방식으로 디지털 성범죄가 일어나고 있다. 이에 불법 촬영물, 비동의 성적 촬영물 등의 촬영 및 유포에 관한 논의가 끊이지 않고 있다. 승리를 포함한 남성 연예인 다수가 포함된 단톡방 사건부터 미성년자 성착취 영상 등이 다수 유포되는 N번방 사건에 이르기까지, 디지털 성범죄는 기승을 부리고 있다. 그러나 디지털 성범죄의 심각성에 대한 사회적 인식에 비해, 디지털 성범죄의 처벌은 미미하다. N번방 성착취에 대한 강력 처벌을 촉구하는 시위도 진행되고 있으나, 이에 대한 공식 입장을 내놓는 정치인의 수는 극히 적다. 문제는 기술의 발전에 따라, 디지털 성범죄 영상이 단순 촬영물에 그치지 않는 데에 있다. 기존 법안에서 다루는 불법 촬영 영상은 피해자의 신체 일부를 직접 촬영한 불법 촬영물 또는 그러한 촬영물의 복제물만을 지칭한다. 그러나 인공지능 기술의 발전에 따라 디지털 성범죄 영상은 이전보다 다양한 형태로 제작되어 유포되고 있다. 직접 촬영한 사진과 영상뿐만 아니라, 기존 음란물에 개인의 얼굴을 합성한 사진과 영상까지도 음란물 사이트에서 소비된다.         트위터, 텀블러 등 해외 기반 SNS 사이트에서는 합성 디지털 성범죄 사례를 쉽게 찾을 수 있다. '지인 능욕', '아헤가오(음란물 속 과장된 여성의 표정을 얼굴과 합성한 사진을 유포하는 행위)' 등이 그에 해당한다. 이를 제작하는 다수의 계정은 지인이나 연예인의 사진을 음란 사진에 합성하고, 유포한다. 심지어 사진을 합성하는 데서 그치지 않고, 해당 사진들에'얼싸(합성한 사진에 정액을 뿌리는 행위)'를 한 사진까지 게재하기도 한다. 사진을 합성할 수 있는 능력만 있으면 누구나 '지인능욕' 등의 사진을 제작해 유포할 수 있다. 제작 과정에서는 연예인의 사진뿐만 아니라, 일반인의 사진까지도 합성의 타겟이 된다. 언론사 보도에 따르면 한 제작 계정의 경우 의뢰인이 삼만 원을 지불하면 일반인은 다섯 장, 연예인은 열 장의 음란물 합성 사진을 제작해 제공한다. 개인 SNS 등에 공개된 일반인의 사진을 이용한 합성 범죄는 끊이지 않는다. 자신의 사진이 합성되어 음란물로 유포되는 것조차 모르는 피해자가 대다수다. 최근에는 기술의 발전으로, 가해 방식이 사진 합성에서 그치지 않는다. 딥페이크 기술을 이용해 영상을 재편집해 성착취 영상을 제작하는 사례가 늘고 있다. 딥페이크(deepfake)는 딥러닝(deep learning)과 가짜(fake)의 합성어로, 인공지능 기술을 이용해 가짜 영상을 제작해내는 기술이다. 딥페이크 영상은 주로 특정 인물의 얼굴을 특정 영상에 합성해 편집된다. 딥페이크 기술이 활용되던 초기에는 정치, 사회 분야 등에서 딥페이크 기술이 가짜 뉴스 제작에 적극적으로 활용될 상황에 대한 우려의 목소리가 컸다. 그러나 딥페이크 기술은 가짜 뉴스 제작보다 음란물 제작에 더 적극적으로 활용되고 있다.         네덜란드 사이버 보안 연구 회사 '딥트레이스'가 2019년 발표한 자료에 따르면, 딥페이크 영상의 96%가 음란물로 소비되었다. 이러한 딥페이크 음란물의 조회수는 1억 3400만 이상에 달한다. 음란물 영상에 합성된 피해자는 100% 여성이었다. 게다가 피해자 여성의 25%는 한국 연예인으로, 미국(41%) 다음으로 그 수가 많다. 국내 여성 아이돌을 타겟으로 한 딥페이크 사이트에서는 여성 아이돌이 그룹별로 정리되어 있으며, 영상을 제작하는 방법까지 상세히 기재되어 있다. 최근에는 딥페이크 제작 앱 등이 일반인에게 배포되며, 딥페이크 영상 제작의 접근성이 낮아졌다. 이로 인해 딥페이크 성착취 영상의 피해자는 여성 연예인뿐만 아니라 일반인 여성으로까지 확장되고 있다. 불법 성착취 합성물의 제작자에게 영상을 의뢰하면 몇 만 원으로 여성의 얼굴이 합성된 사진, 영상을 구매할 수 있다. 불법 촬영물, 비동의 성적 촬영물의 유포 등 디지털 성범죄는 '성폭력범죄의처벌등에관한특례법'을 근거로 처벌한다. 그러나 해당 법안은 직접 촬영한 영상에 대해서만 처벌이 가능하다. 즉 합성을 통해 제작된 '지인 능욕' 사진, 딥페이크 성착취 영상의 제작 및 유포는 성범죄로 처벌하는 것이 현행법상 불가능하다. 따라서 딥페이크 성착취 영상의 제작자, 유포자는 우회 처벌만 가능한 실정이다. 형법 244조에 의거해 '음란한 물건'을 제조한 경우에 관한 처벌, 정보통신망법 중 음란한 영상을 배포하거나 전시하는 경우에 관한 처벌, 명예훼손에 대한 처벌 등을 적용할 수 있다. 그러나 해당 법안에 의한 처벌의 경우 대부분 벌금형이나 집행유예에 그친다. 딥페이크 성착취 영상은 여성의 성적 자기 결정권을 침해해 동의 없이 음란물을 제작하고 유포하는 명백한 성범죄이다. 그럼에도 법적으로 딥페이크 영상이 성범죄로 명시되지 않아 딥페이크 제작, 유통, 소비 가해자들이 성범죄자로 분류되지 않는다. 딥페이크 성착취 영상은 피해자의 의사와 무관하게 제작되며, 불특정 다수에게 배포된다. 기술이 발전하며 영상이 정교해지기 때문에 합성된 영상이라는 것을 알아차리기도 어려워져 자칫 합성 영상이 아니라고 인식될 수도 있다. 딥페이크 성착취 영상의 제작과 유포를 처벌하는 법안을 도입하고자 하는 움직임은 지속적으로 이루어졌다. 최근 출범한 여성폭력방지위원회가 추진하는 법안 중 하나도 딥페이크 영상에 대한 처벌 법안이다. 특히 최근 국회에 발의된 성폭력처벌법 개정안에 의하면, 재편집물까지 디지털 성범죄 영상으로 포함해 처벌한다는 조항이 명시되어 있다. 그러나 국회에 발의된 개정안이 도입되더라도 처벌이 즉각적으로 이루어지기는 어려워 보인다. 대부분의 딥페이크 영상은 외국에 기반을 둔 사이트를 중심으로 유통이 이루어지기 때문에 범죄자의 추적이 쉽지 않다. 해외 사이트의 협조가 필요하나 협조를 해주지 않는 경우가 많고, 협력이 이루어진다고 해도 진행 과정에서 오랜 시간이 걸리기 때문이다. 그렇기 때문에 해외 사이트 또는 해외 국가에 적극적으로 협조를 요청할 수 있는 구체적 방안을 마련할 필요가 있다. 이러한 한계에 대한 보완 등을 위해 디지털 성범죄와 관련한 국제 공조 수사, 전담 부서와 대응 매뉴얼 제작, 양형기준 재조정을 요구하는 청원이 국회 홈페이지에 올라와 동의 100%를 달성했다. 그러나 법안심사소위원회에서 3월 4일 심사한 내용에 따르면, 기존의 개정안에 청원의 취지가 반영되었으므로 청원을 본회의에 부의하지 않아도 된다고 결정되었다. 막연히 청원의 취지가 개정 법률안에 반영되었다고 진술하는 것으로는 앞서 언급된 문제들을 해결하기 위한 법적 강제 조치를 취하기는 어려워 보인다. 그렇게 되면 법률이 개정되어도 실질적으로 피해자의 신고와 수사 절차의 진행 등이 이루어지기는 어렵다. 게다가 기존의 디지털 성범죄 처벌 법안에서는 제작자와 배포자에 대한 처벌 조항은 있지만, 영상을 시청하거나 저장한 경우에 대한 처벌 조항은 부재한다. 그러나 불법 성착취 영상의 제작과 유포는 수요를 기반으로 한 것인 만큼 영상 소비자에 대한 처벌이 필수적이다. 영상의 시청과 저장 과정에서 영상의 피해자에게 이루어지는 성희롱 등도 중대한 성범죄로 분류되어 처벌의 대상이 되어야 한다. 불법 촬영물, 딥페이크 영상 등 디지털 성범죄에 대한 법안 확대와 처벌 강화에 대한 요구는 몇 년 동안 끊이지 않고 있다. 그러나 구체적으로 실현 가능성이 있는 정책이 진행되지는 않고 있으며 국가적 차원에서의 논의 또한 범죄 처벌 강화에 그친다. 불법 촬영물에 대한 조직적 신고와 모니터링은 DSO('디지털 성범죄 아웃'의 줄임말로, 디지털 성범죄에 대응하는 단체) 등 민간 단체와 봉사자들에 의해 주로 이루어졌다. 그러나 민간 단체에서 활동을 지속하기에는 정신적, 경제적으로 한계가 뒤따른다. DSO 또한 2019년 12월, 활동가 수의 부족과 경제적 어려움을 근거로 단체 해산을 발표했다. 정부의 주도 하에 음란물 사이트를 대상으로 지속적인 감시를 진행하는 단체를 조직하고 예산을 지원해야 한다. 과거 공개된 음란물 웹하드 업체 관련 권력 구조도에 따르면, 불법 유포된 음란물을 삭제해주는 업체마저 음란물 유포 사이트와 결탁해 경제적 이익을 취하고 있었다. 따라서 모니터링 이후, 영상의 삭제 과정에도 정부의 적극적인 개입이 필요하다. 가해자에 대한 처벌, 온라인 상의 영상에 관한 관리 외에 피해자와 활동가를 위한 지원 또한 필요하다. 디지털 성범죄 신고를 위해 음란물 사이트를 지속적으로 모니터링한 활동가들 중 많은 이들이 범죄 영상 노출로 인한 정신적 피로를 호소했다. 디지털 성범죄를 경험한 피해자를 위해 여성 단체 등과 협조해 피해 상담 지원도 이루어져야 한다. 디지털 성범죄 피해 여성들이 범죄에 대응하지 않은 이유 중 대응 절차와 방법을 이유로 꼽은 만큼 이에 관한 해결도 요구된다. 디지털 성범죄 전담 수사팀을 확대해 운영할 필요가 있으며 디지털 성범죄를 전담하지 않는 경찰을 대상으로 주기적으로 디지털 성범죄 관련 교육을 시행해야 한다. 특히 피해자가 신고할 때의 대응 매뉴얼을 제작해 배포하고, 신고 거부에 대한 징계와 2차 가해 방지를 위한 노력을 이뤄나가야 한다. 디지털 성범죄의 심각성에 관한 논의와 해결을 향한 사회적 요구는 이미 충분한 수준에 다다랐다. 이제는 국가적 차원에서 구체적 노력이 필요한 상황이다. 디지털 성범죄는 민간 여성 단체와 여성가족부가 떠맡아야 하는 문제가 아니다. AI 기술 전문가, 경찰, 국회, 정부, 사법부 등 모든 기관들이 힘을 합쳐 해결해야 하는 문제다. AI 개발 관계자는 디지털 성범죄에도 불구하고 AI 기술의 발전을 위해 딥페이크 기술의 민간 공개가 필요하다고 말했다. 그러나 성폭력을 통해 이루어낸 발전 이후의 세계에서 과연 기술이 인간을 위해 사용될지는 의문이 든다.글  정진아·오서영 / 바람 저널리스트저작권자(c) 오마이뉴스(시민기자), 무단 전재 및 재배포 금지
오마이뉴스
